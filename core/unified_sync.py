# Ø§Ù„Ù…Ù„Ù: core/unified_sync.py
"""
ğŸ”„ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…ÙˆØ­Ø¯ - MongoDB First
MongoDB Ù‡Ùˆ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØŒ SQLite Ù†Ø³Ø®Ø© Ù…Ø­Ù„ÙŠØ© Ù„Ù„Ù€ offline ÙÙ‚Ø·

Ø§Ù„Ù…Ø¨Ø¯Ø£:
- Ø¹Ù†Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„: MongoDB = Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø© Ø§Ù„Ù…Ø·Ù„Ù‚Ø©
- Ø¹Ù†Ø¯ Ø¹Ø¯Ù… Ø§Ù„Ø§ØªØµØ§Ù„: SQLite ÙŠØ­ÙØ¸ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ù…Ø¤Ù‚ØªØ§Ù‹
- Ø¹Ù†Ø¯ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„: Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø«Ù… Ù…Ø³Ø­ ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ù…Ù† MongoDB
"""

import json
import threading
from datetime import datetime
from typing import Any

from PyQt6.QtCore import QObject, QTimer, pyqtSignal

from core.logger import get_logger

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¯Ø§Ù„Ø© Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¢Ù…Ù†Ø©
try:
    from core.safe_print import safe_print
except ImportError:

    def safe_print(msg):
        try:
            print(msg)
        except UnicodeEncodeError:
            pass


logger = get_logger(__name__)

# ==================== Ø«ÙˆØ§Ø¨Øª Ø§Ù„ØªÙˆÙ‚ÙŠØª (Ø¨Ø§Ù„Ù…Ù„Ù„ÙŠ Ø«Ø§Ù†ÙŠØ©) ====================
FULL_SYNC_INTERVAL_MS = 15 * 60 * 1000
QUICK_SYNC_INTERVAL_MS = 3 * 60 * 1000
CONNECTION_CHECK_INTERVAL_MS = 90 * 1000
CLOUD_PULL_INTERVAL_MS = 45 * 1000


class UnifiedSyncManagerV3(QObject):
    """
    Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…ÙˆØ­Ø¯ - MongoDB First Architecture
    Ù…Ø¹ Ù†Ø¸Ø§Ù… Ù…Ø²Ø§Ù…Ù†Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø§Ø­ØªØ±Ø§ÙÙŠ
    """

    # Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
    sync_started = pyqtSignal()
    sync_progress = pyqtSignal(str, int, int)  # table, current, total
    sync_completed = pyqtSignal(dict)
    sync_error = pyqtSignal(str)
    connection_changed = pyqtSignal(bool)  # online/offline
    data_synced = pyqtSignal()  # âš¡ NEW: Signal emitted after successful pull for UI refresh

    # Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    TABLES = [
        "accounts",
        "clients",
        "services",
        "projects",
        "invoices",
        "payments",
        "expenses",
        "journal_entries",
        "currencies",
        "notifications",
        "tasks",
    ]

    # Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù„ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
    UNIQUE_FIELDS = {
        "clients": "name",
        "projects": "name",
        "services": "name",
        "accounts": "code",
        "invoices": "invoice_number",
        "payments": "id",
        "expenses": "id",
        "journal_entries": "id",
        "currencies": "code",
        "users": "username",
        "notifications": "id",
        "tasks": "id",
    }

    def __init__(self, repository, parent=None):
        super().__init__(parent)
        self.repo = repository
        self._lock = threading.RLock()
        self._is_syncing = False
        self._max_retries = 3
        self._last_online_status = None
        self._shutdown = False  # âš¡ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø¥ØºÙ„Ø§Ù‚
        self._last_full_sync_at = None

        # âš¡ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© - Ù…ÙØ¹Ù‘Ù„Ø© Ù„Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©
        self._auto_sync_enabled = True
        self._auto_sync_interval = FULL_SYNC_INTERVAL_MS
        self._quick_sync_interval = QUICK_SYNC_INTERVAL_MS
        self._connection_check_interval = CONNECTION_CHECK_INTERVAL_MS

        # âš¡ Ø§Ù„Ù…Ø¤Ù‚ØªØ§Øª
        self._auto_sync_timer = None
        self._quick_sync_timer = None
        self._connection_timer = None
        self._cloud_pull_timer = None
        self._delta_pull_timer = None  # âš¡ NEW: Ù…Ø¤Ù‚Øª Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„ØªÙØ§Ø¶Ù„ÙŠ

        # âš¡ Watermarks Ù„Ù„Ù€ Delta Sync
        self._watermarks: dict[str, str] = {}
        self._load_watermarks()

        logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© UnifiedSyncManager - Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡")

    def _check_mongodb_connection(self) -> bool:
        try:
            if not self.is_online:
                return False
            if self.repo.mongo_db is None or self.repo.mongo_client is None:
                logger.warning("MongoDB client Ø£Ùˆ database ØºÙŠØ± Ù…ØªÙˆÙØ±")
                return False
            self.repo.mongo_client.admin.command("ping", maxTimeMS=5000)
            server_info = self.repo.mongo_client.server_info()
            if not server_info:
                logger.warning("ÙØ´Ù„ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø®Ø§Ø¯Ù…")
                return False
            return True
        except Exception as e:
            error_msg = str(e).lower()
            if "cannot use mongoclient after close" in error_msg:
                logger.debug("MongoDB client Ù…ØºÙ„Ù‚")
            elif "serverselectiontimeout" in error_msg:
                logger.debug("Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ MongoDB")
            elif "network" in error_msg or "connection" in error_msg:
                logger.debug("Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© Ù…Ø¹ MongoDB")
            else:
                logger.warning("Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ MongoDB: %s", e)
            return False

    def _safe_mongodb_operation(self, operation_func, *args, **kwargs):
        try:
            if not self._check_mongodb_connection():
                return None
            return operation_func(*args, **kwargs)
        except Exception as e:
            logger.error("ÙØ´Ù„ Ø¹Ù…Ù„ÙŠØ© MongoDB: %s", e, exc_info=True)
            return None

    # ==========================================
    # ğŸš€ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙÙˆØ±ÙŠØ© - Real-time Sync
    # ==========================================

    def instant_sync(self, table: str = None):
        """
        âš¡ Ù…Ø²Ø§Ù…Ù†Ø© ÙÙˆØ±ÙŠØ© Ù„Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ Ø£Ùˆ ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„

        Args:
            table: Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ). Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØ­Ø¯Ø¯ØŒ ÙŠØªÙ… Ù…Ø²Ø§Ù…Ù†Ø© ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        """
        if self._shutdown or not self.is_online:
            return

        try:
            if table:
                # Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯
                self._sync_single_table_to_cloud(table)
                self._sync_single_table_from_cloud(table)
                logger.debug("âš¡ ØªÙ… Ù…Ø²Ø§Ù…Ù†Ø© %s ÙÙˆØ±Ø§Ù‹", table)
            else:
                self._push_pending_changes()
                for table_name in self.TABLES:
                    self._sync_single_table_from_cloud(table_name)
                logger.debug("âš¡ ØªÙ… Ù…Ø²Ø§Ù…Ù†Ø© ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙÙˆØ±Ø§Ù‹")
        except Exception as e:
            logger.debug("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙÙˆØ±ÙŠØ©: %s", e)

    def _sync_single_table_from_cloud(self, table: str):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©"""
        if not self.is_online or self.repo is None or self.repo.mongo_db is None:
            return

        if table not in self.TABLES:
            return

        try:
            self._sync_table_from_cloud(table)
        except Exception as e:
            logger.debug("Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© %s Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©: %s", table, e)

    def _sync_single_table_to_cloud(self, table: str):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ ÙÙˆØ±Ø§Ù‹"""
        if not self.is_online or self.repo is None or self.repo.mongo_db is None:
            return

        # âš¡ ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        if table not in self.TABLES:
            return

        try:
            # âš¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… cursor Ù…Ù†ÙØµÙ„ Ù„ØªØ¬Ù†Ø¨ Recursive cursor error
            cursor = self.repo.get_cursor()
            try:
                # âš¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹
                cursor.execute(
                    "SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table,)
                )
                if not cursor.fetchone():
                    return  # Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯

                cursor.execute(
                    f"SELECT * FROM {table} WHERE sync_status != 'synced' OR sync_status IS NULL"
                )
                rows = cursor.fetchall()

                if not rows:
                    return

                columns = [desc[0] for desc in cursor.description]
                collection = self.repo.mongo_db[table]

                updated_any = False
                for row in rows:
                    record = dict(zip(columns, row, strict=False))
                    mongo_id = record.get("_mongo_id")

                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    clean_record = {
                        k: v
                        for k, v in record.items()
                        if k not in ["id", "sync_status", "last_synced"]
                    }

                    if mongo_id:
                        # ØªØ­Ø¯ÙŠØ«
                        from bson import ObjectId

                        collection.update_one(
                            {"_id": ObjectId(mongo_id)}, {"$set": clean_record}, upsert=True
                        )
                    else:
                        # Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯
                        result = collection.insert_one(clean_record)
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ mongo_id Ù…Ø­Ù„ÙŠØ§Ù‹
                        cursor.execute(
                            f"UPDATE {table} SET _mongo_id = ?, sync_status = 'synced' WHERE id = ?",
                            (str(result.inserted_id), record.get("id")),
                        )
                        updated_any = True

                    # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
                    cursor.execute(
                        f"UPDATE {table} SET sync_status = 'synced' WHERE id = ?",
                        (record.get("id"),),
                    )
                    updated_any = True
                if updated_any:
                    self.repo.sqlite_conn.commit()
            finally:
                cursor.close()

        except Exception as e:
            logger.debug("ØªØ¬Ø§Ù‡Ù„ Ø®Ø·Ø£ Ù…Ø²Ø§Ù…Ù†Ø© %s: %s", table, e)

    # ==========================================
    # Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ
    # ==========================================

    def start_auto_sync(self):
        """ğŸš€ Ø¨Ø¯Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
        if not self._auto_sync_enabled:
            return

        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©...")

        # 1. Ù…Ø¤Ù‚Øª ÙØ­Øµ Ø§Ù„Ø§ØªØµØ§Ù„ (ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©)
        self._connection_timer = QTimer(self)
        self._connection_timer.timeout.connect(self._check_connection)
        self._connection_timer.start(self._connection_check_interval)

        # 2. Ù…Ø¤Ù‚Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© Ù„Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© (ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©)
        self._quick_sync_timer = QTimer(self)
        self._quick_sync_timer.timeout.connect(self._quick_push_changes)
        self._quick_sync_timer.start(self._quick_sync_interval)

        # 3. Ù…Ø¤Ù‚Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© (ÙƒÙ„ 5 Ø¯Ù‚Ø§Ø¦Ù‚)
        self._auto_sync_timer = QTimer(self)
        self._auto_sync_timer.timeout.connect(self._auto_full_sync)
        self._auto_sync_timer.start(self._auto_sync_interval)

        self._cloud_pull_timer = QTimer(self)
        self._cloud_pull_timer.timeout.connect(self._cloud_pull_changes)
        self._cloud_pull_timer.start(CLOUD_PULL_INTERVAL_MS)

        # 4. Ù…Ø²Ø§Ù…Ù†Ø© Ø£ÙˆÙ„ÙŠØ© Ø¨Ø¹Ø¯ 5 Ø«ÙˆØ§Ù†ÙŠ
        QTimer.singleShot(5000, self._initial_sync)

        # 5. âš¡ NEW: Ø¨Ø¯Ø¡ Delta Sync ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ© Ù„Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©
        self.start_delta_sync(interval_seconds=60)

        logger.info("â° Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©: ÙƒÙ„ %s Ø¯Ù‚ÙŠÙ‚Ø©", self._auto_sync_interval // 60000)
        logger.info("â° Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª: ÙƒÙ„ %s Ø¯Ù‚ÙŠÙ‚Ø©", self._quick_sync_interval // 60000)
        logger.info("â° Delta Sync: ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ©")

    def stop_auto_sync(self):
        """â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
        logger.info("â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©...")
        self._shutdown = True  # âš¡ ØªØ¹ÙŠÙŠÙ† Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø¥ØºÙ„Ø§Ù‚

        # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¤Ù‚ØªØ§Øª Ø¨Ø£Ù…Ø§Ù†
        try:
            if self._auto_sync_timer:
                try:
                    self._auto_sync_timer.stop()
                except (RuntimeError, AttributeError):
                    pass
                self._auto_sync_timer = None
        except Exception:
            pass

        try:
            if self._quick_sync_timer:
                try:
                    self._quick_sync_timer.stop()
                except (RuntimeError, AttributeError):
                    pass
                self._quick_sync_timer = None
        except Exception:
            pass

        try:
            if self._cloud_pull_timer:
                try:
                    self._cloud_pull_timer.stop()
                except (RuntimeError, AttributeError):
                    pass
                self._cloud_pull_timer = None
        except Exception:
            pass

        try:
            if self._connection_timer:
                try:
                    self._connection_timer.stop()
                except (RuntimeError, AttributeError):
                    pass
                self._connection_timer = None
        except Exception:
            pass

        logger.info("âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©")

    def stop(self):
        self.stop_auto_sync()

    def _check_connection(self):
        """ğŸ”Œ ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ - Ù…Ø­Ø³Ù‘Ù†"""
        if self._shutdown:  # âš¡ ØªØ¬Ø§Ù‡Ù„ Ø¥Ø°Ø§ ØªÙ… Ø§Ù„Ø¥ØºÙ„Ø§Ù‚
            return

        try:
            # âš¡ ÙØ­Øµ Ø£Ù† MongoDB client Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…ØªØ§Ø­Ø§Ù‹ Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
            if self.repo is None or self.repo.mongo_client is None or self.repo.mongo_db is None:
                current_status = False
            else:
                try:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© ping Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø§ØªØµØ§Ù„ ÙØ¹Ø§Ù„
                    self.repo.mongo_client.admin.command("ping")
                    current_status = True
                except Exception:
                    current_status = False

            # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© Ø¹Ù†Ø¯ ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø§Ù„Ø© ÙÙ‚Ø·
            if current_status != self._last_online_status:
                self._last_online_status = current_status
                try:
                    if not self._shutdown:
                        self.connection_changed.emit(current_status)
                except RuntimeError:
                    return  # Qt object deleted

                if current_status:
                    logger.info("ğŸŸ¢ ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„")
                    QTimer.singleShot(300, self._run_full_sync_async)
                else:
                    logger.warning("ğŸ”´ Ø§Ù†Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„ - Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ ÙˆØ¶Ø¹ Offline")
        except Exception:
            # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            pass

    def _initial_sync(self):
        """ğŸš€ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„ - ØªÙØ§Ø¶Ù„ÙŠØ© Ù„Ù„Ø³Ø±Ø¹Ø©"""
        if self._shutdown:
            return

        if not self.is_online:
            logger.info("ğŸ“´ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØµØ§Ù„ - Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©")
            return

        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")

        def sync_thread():
            if self._shutdown:
                return
            try:
                result = self.full_sync_from_cloud()
                if result.get("success"):
                    logger.info("âœ… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: ØªÙ… ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„ÙƒØ§Ù…Ù„")
                else:
                    logger.warning("âš ï¸ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù„Ù… ØªÙƒØªÙ…Ù„: %s", result.get("reason"))
            except Exception as e:
                logger.warning("âš ï¸ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: %s", e)

        # Ø§Ø³ØªØ®Ø¯Ø§Ù… QTimer Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† daemon thread
        threading.Thread(target=sync_thread, daemon=True).start()

    def _auto_full_sync(self):
        """ğŸ”„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© - ØªÙØ§Ø¶Ù„ÙŠØ© Ù„Ù„Ø³Ø±Ø¹Ø©"""
        if self._shutdown or self._is_syncing or not self.is_online:
            return

        self._run_full_sync_async()

    def _quick_push_changes(self):
        """âš¡ Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø¨Ø³Ø±Ø¹Ø©"""
        if self._shutdown or self._is_syncing or not self.is_online:
            return

        try:
            # âš¡ Ø¥Ù†Ø´Ø§Ø¡ cursor Ø¬Ø¯ÙŠØ¯ Ù„ØªØ¬Ù†Ø¨ Recursive cursor error
            cursor = self.repo.get_cursor()
            has_pending = False

            try:
                for table in self.TABLES:
                    try:
                        cursor.execute(
                            f"""
                            SELECT COUNT(*) FROM {table}
                            WHERE sync_status != 'synced' OR sync_status IS NULL
                        """
                        )
                        count = cursor.fetchone()[0]
                        if count > 0:
                            has_pending = True
                            break
                    except Exception:
                        # ÙØ´Ù„ ÙØ­Øµ Ø§Ù„Ø¹Ù†ØµØ±
                        pass
            finally:
                cursor.close()  # âš¡ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù€ cursor

            if has_pending:

                def push_thread():
                    if self._shutdown:
                        return
                    try:
                        with self._lock:
                            self._push_pending_changes()
                        logger.debug("âš¡ ØªÙ… Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©")
                    except Exception as e:
                        logger.error("âŒ ÙØ´Ù„ Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª: %s", e)

                threading.Thread(target=push_thread, daemon=True).start()

        except Exception as e:
            logger.debug("Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª: %s", e)

    def set_auto_sync_interval(self, minutes: int):
        """â° ØªØºÙŠÙŠØ± ÙØªØ±Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©"""
        self._auto_sync_interval = minutes * 60 * 1000
        if self._auto_sync_timer:
            self._auto_sync_timer.setInterval(self._auto_sync_interval)
        logger.info("â° ØªÙ… ØªØºÙŠÙŠØ± ÙØªØ±Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø¥Ù„Ù‰ %s Ø¯Ù‚ÙŠÙ‚Ø©", minutes)

    @property
    def is_online(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ ÙØ­Øµ Ø­Ø§Ù„Ø© MongoDB client"""
        if self.repo is None:
            return False

        # âš¡ ÙØ­Øµ Ø£Ù† MongoDB client Ù…ØªØ§Ø­ ÙˆÙ„Ù… ÙŠÙØºÙ„Ù‚
        if self.repo.mongo_client is None or self.repo.mongo_db is None:
            return False

        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© ping Ø³Ø±ÙŠØ¹Ø© Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø§ØªØµØ§Ù„ ÙØ¹Ø§Ù„
            self.repo.mongo_client.admin.command("ping")
            return True
        except Exception:
            return False

    def _wait_for_connection(self, timeout: int = 10) -> bool:
        """âš¡ Ø§Ù†ØªØ¸Ø§Ø± Ø§ØªØµØ§Ù„ MongoDB Ù…Ø¹ timeout"""
        import time

        waited = 0
        while not self.is_online and waited < timeout:
            time.sleep(0.5)
            waited += 0.5
        return self.is_online

    def _run_full_sync_async(self):
        if self._shutdown or self._is_syncing or not self.is_online:
            return

        def worker():
            if self._shutdown:
                return
            try:
                self._last_full_sync_at = datetime.now()
                self.full_sync_from_cloud()
            except Exception as e:
                logger.debug("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©: %s", e)

        threading.Thread(target=worker, daemon=True).start()

    def _cloud_pull_changes(self):
        if self._shutdown or not self.is_online:
            return
        if self._last_full_sync_at:
            if (datetime.now() - self._last_full_sync_at).total_seconds() < 30:
                return
        self._run_full_sync_async()

    def full_sync_from_cloud(self) -> dict[str, Any]:
        """
        Ù…Ø²Ø§Ù…Ù†Ø© ÙƒØ§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø© - MongoDB Ù‡Ùˆ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙˆØ­ÙŠØ¯
        ÙŠØ­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
        """
        # âš¡ ÙØ­Øµ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø£ÙˆÙ„Ø§Ù‹
        if self._shutdown:
            return {"success": False, "reason": "shutdown"}

        # âš¡ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø£ÙˆÙ„Ø§Ù‹
        if not self._wait_for_connection(timeout=10):
            logger.warning("ØºÙŠØ± Ù…ØªØµÙ„ - Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©")
            return {"success": False, "reason": "offline"}

        if self._is_syncing:
            return {"success": False, "reason": "already_syncing"}

        # âš¡ ÙØ­Øµ ÙØ¹Ù„ÙŠ Ø£Ù† MongoDB client Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…ØªØ§Ø­Ø§Ù‹
        if self.repo is None or self.repo.mongo_client is None or self.repo.mongo_db is None:
            return {"success": False, "reason": "no_mongo_client"}

        try:
            self.repo.mongo_client.admin.command("ping")
        except Exception:
            logger.debug("MongoDB client Ù…ØºÙ„Ù‚ - ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©")
            return {"success": False, "reason": "mongo_client_closed"}

        self._is_syncing = True
        self.sync_started.emit()

        results = {"success": True, "tables": {}, "total_synced": 0, "total_deleted": 0}

        try:
            with self._lock:
                # 1. Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
                self._push_pending_changes()

                # 2. Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
                self._sync_users_from_cloud()

                # 3. Ù…Ø²Ø§Ù…Ù†Ø© ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
                for table in self.TABLES:
                    try:
                        stats = self._sync_table_from_cloud(table)
                        results["tables"][table] = stats
                        results["total_synced"] += stats.get("synced", 0)
                        results["total_deleted"] += stats.get("deleted", 0)
                    except Exception as e:
                        logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© %s: %s", table, e)
                        results["tables"][table] = {"error": str(e)}

            logger.info("âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©: %s Ø³Ø¬Ù„", results["total_synced"])
            self.sync_completed.emit(results)

            # âš¡ Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø£Ø±ØµØ¯Ø© Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ù‚Ø¯ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
            try:
                from services.accounting_service import AccountingService

                # Ø¥Ø¨Ø·Ø§Ù„ Ø§Ù„Ù€ cache Ø£ÙˆÙ„Ø§Ù‹
                AccountingService._hierarchy_cache = None
                AccountingService._hierarchy_cache_time = 0
                logger.info("ğŸ“Š ØªÙ… Ø¥Ø¨Ø·Ø§Ù„ cache Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª - Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¹Ù†Ø¯ ÙØªØ­ ØªØ§Ø¨ Ø§Ù„Ù…Ø­Ø§Ø³Ø¨Ø©")
            except Exception as e:
                logger.warning("âš ï¸ ÙØ´Ù„ Ø¥Ø¨Ø·Ø§Ù„ cache Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª: %s", e)

            # âš¡ Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø§Øª ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
            try:
                from core.signals import app_signals

                app_signals.emit_data_changed("clients")
                app_signals.emit_data_changed("projects")
                app_signals.emit_data_changed("accounts")
                app_signals.emit_data_changed("payments")
                app_signals.emit_data_changed("expenses")
                logger.info("ğŸ“¢ ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø§Øª ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©")
            except Exception as e:
                logger.warning("âš ï¸ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ­Ø¯ÙŠØ«: %s", e)

        except Exception as e:
            logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©: %s", e)
            results["success"] = False
            results["error"] = str(e)
            self.sync_error.emit(str(e))

        finally:
            self._is_syncing = False

        return results

    def _sync_table_from_cloud(self, table_name: str) -> dict[str, int]:
        """
        Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø© Ù…Ø¹ Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        """
        stats = {"synced": 0, "inserted": 0, "updated": 0, "deleted": 0, "linked": 0}

        try:
            # âš¡ ÙØ­Øµ Ø§Ù„Ø§ØªØµØ§Ù„ Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… MongoDB
            if self._shutdown:
                return stats

            if self.repo is None or not self.repo.online:
                return stats

            # âš¡ ÙØ­Øµ Ø£Ù† MongoDB client Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…ØªØ§Ø­Ø§Ù‹
            if self.repo.mongo_db is None or self.repo.mongo_client is None:
                return stats

            # âš¡ ÙØ­Øµ ÙØ¹Ù„ÙŠ Ø£Ù† Ø§Ù„Ù€ client Ù„Ù… ÙŠÙØºÙ„Ù‚
            try:
                # Ù…Ø­Ø§ÙˆÙ„Ø© ping Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø§ØªØµØ§Ù„ ÙØ¹Ø§Ù„
                self.repo.mongo_client.admin.command("ping")
            except Exception:
                logger.debug(
                    "ØªÙ… ØªØ®Ø·ÙŠ Ù…Ø²Ø§Ù…Ù†Ø© %s - MongoDB client Ù…ØºÙ„Ù‚ Ø£Ùˆ ØºÙŠØ± Ù…ØªØ§Ø­",
                    table_name,
                )
                return stats

            # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
            try:
                cloud_data = list(self.repo.mongo_db[table_name].find())
            except Exception as mongo_err:
                error_msg = str(mongo_err)
                if (
                    "Cannot use MongoClient after close" in error_msg
                    or "InvalidOperation" in error_msg
                ):
                    logger.debug("ØªÙ… ØªØ®Ø·ÙŠ Ù…Ø²Ø§Ù…Ù†Ø© %s - MongoDB client Ù…ØºÙ„Ù‚", table_name)
                    return stats
                raise

            if not cloud_data:
                logger.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ %s", table_name)
                return stats

            # âš¡ Ø¥Ù†Ø´Ø§Ø¡ cursor Ø¬Ø¯ÙŠØ¯ Ù„ØªØ¬Ù†Ø¨ Recursive cursor error
            cursor = self.repo.get_cursor()
            conn = self.repo.sqlite_conn
            unique_field = self.UNIQUE_FIELDS.get(table_name, "name")

            try:
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„
                cursor.execute(f"PRAGMA table_info({table_name})")
                table_columns = {row[1] for row in cursor.fetchall()}

                # Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù€ mongo_ids Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
                cloud_mongo_ids = set()

                for i, cloud_item in enumerate(cloud_data):
                    self.sync_progress.emit(table_name, i + 1, len(cloud_data))

                    mongo_id = str(cloud_item["_id"])
                    cloud_mongo_ids.add(mongo_id)
                    unique_value = cloud_item.get(unique_field)

                    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    item_data = self._prepare_cloud_data(cloud_item)
                    item_data["_mongo_id"] = mongo_id
                    item_data["sync_status"] = "synced"

                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ
                    local_id = self._find_local_record(
                        cursor, table_name, mongo_id, unique_field, unique_value, table_columns
                    )

                    # ØªØµÙÙŠØ© Ø§Ù„Ø­Ù‚ÙˆÙ„
                    filtered = {k: v for k, v in item_data.items() if k in table_columns}

                    # âš¡ ØªØ³Ø¬ÙŠÙ„ Ù„Ùˆ logo_data Ù…ÙˆØ¬ÙˆØ¯
                    if (
                        table_name == "clients"
                        and "logo_data" in item_data
                        and item_data["logo_data"]
                    ):
                        if "logo_data" in filtered:
                            logger.info(
                                "ğŸ“· [%s] logo_data Ø³ÙŠØªÙ… Ø­ÙØ¸Ù‡ (%s Ø­Ø±Ù)",
                                unique_value,
                                len(filtered["logo_data"]),
                            )
                        else:
                            logger.warning(
                                "âš ï¸ [%s] logo_data ØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡! (ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„)",
                                unique_value,
                            )
                            logger.warning("   Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„: %s", table_columns)

                    if local_id:
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
                        self._update_record(cursor, table_name, local_id, filtered)
                        stats["updated"] += 1
                    else:
                        # Ø¥Ø¯Ø±Ø§Ø¬ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯
                        self._insert_record(cursor, table_name, filtered)
                        stats["inserted"] += 1

                    stats["synced"] += 1

                # Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
                deleted = self._delete_orphan_records(cursor, table_name, cloud_mongo_ids)
                stats["deleted"] = deleted

                conn.commit()
                logger.info(
                    "âœ… %s: +%s ~%s -%s",
                    table_name,
                    stats["inserted"],
                    stats["updated"],
                    stats["deleted"],
                )

            finally:
                # âš¡ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù€ cursor
                try:
                    cursor.close()
                except Exception:
                    pass

        except Exception as e:
            logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© %s: %s", table_name, e)
            # âš¡ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù€ cursor ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
            try:
                cursor.close()
            except Exception:
                pass

        return stats

    def _find_local_record(
        self,
        cursor,
        table_name: str,
        mongo_id: str,
        unique_field: str,
        unique_value: Any,
        table_columns: set,
    ) -> int | None:
        """
        Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¨Ø¹Ø¯Ø© Ø·Ø±Ù‚ Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        """
        try:
            # 1. Ø§Ù„Ø¨Ø­Ø« Ø¨Ù€ _mongo_id Ø£ÙˆÙ„Ø§Ù‹
            cursor.execute(f"SELECT id FROM {table_name} WHERE _mongo_id = ?", (mongo_id,))
            row = cursor.fetchone()
            if row:
                return row[0]

            # 2. Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„ÙØ±ÙŠØ¯ - ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ mongo_id
            if unique_value and unique_field in table_columns:
                cursor.execute(
                    f"SELECT id, _mongo_id FROM {table_name} WHERE {unique_field} = ?",
                    (unique_value,),
                )
                row = cursor.fetchone()
                if row:
                    local_id = row[0]
                    existing_mongo_id = row[1]

                    # âš¡ Ø¥ØµÙ„Ø§Ø­: ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ mongo_id Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø®ØªÙ„Ù
                    if existing_mongo_id != mongo_id:
                        cursor.execute(
                            f"UPDATE {table_name} SET _mongo_id = ? WHERE id = ?",
                            (mongo_id, local_id),
                        )
                    return local_id
        except Exception as e:
            logger.debug("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„: %s", e)

        return None

    def _delete_orphan_records(self, cursor, table_name: str, valid_mongo_ids: set) -> int:
        """
        Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
        (Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ _mongo_id Ù„ÙƒÙ†Ù‡ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©)
        """
        if not valid_mongo_ids:
            return 0

        # Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ _mongo_id
        cursor.execute(f"SELECT id, _mongo_id FROM {table_name} WHERE _mongo_id IS NOT NULL")
        local_records = cursor.fetchall()

        deleted = 0
        for row in local_records:
            local_id = row[0]
            local_mongo_id = row[1]

            if local_mongo_id and local_mongo_id not in valid_mongo_ids:
                cursor.execute(f"DELETE FROM {table_name} WHERE id = ?", (local_id,))
                deleted += 1
                logger.debug("Ø­Ø°Ù Ø³Ø¬Ù„ ÙŠØªÙŠÙ…: %s/%s", table_name, local_id)

        return deleted

    def _prepare_cloud_data(self, data: dict) -> dict:
        """ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø­Ø§Ø¨Ø© Ù„Ù„Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹"""
        item = dict(data)
        item.pop("_id", None)
        item.pop("id", None)

        # âš¡ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¬Ù„Ø¨ logo_data Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
        if "logo_data" in data and data["logo_data"]:
            item["logo_data"] = data["logo_data"]
            client_name = data.get("name", "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
            logger.info(
                "ğŸ“· [%s] Ø¬Ù„Ø¨ logo_data (%s Ø­Ø±Ù) Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©",
                client_name,
                len(data["logo_data"]),
            )
            safe_print(
                f"INFO: ğŸ“· [{client_name}] Ø¬Ù„Ø¨ logo_data ({len(data['logo_data'])} Ø­Ø±Ù) Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©"
            )

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        date_fields = [
            "created_at",
            "last_modified",
            "date",
            "issue_date",
            "due_date",
            "expiry_date",
            "start_date",
            "end_date",
            "last_attempt",
            "expires_at",
            "last_login",
        ]
        for field in date_fields:
            if field in item and hasattr(item[field], "isoformat"):
                item[field] = item[field].isoformat()

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… ÙˆØ§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø¥Ù„Ù‰ JSON
        json_fields = ["items", "lines", "data", "milestones"]
        for field in json_fields:
            if field in item and isinstance(item[field], list | dict):
                item[field] = json.dumps(item[field], ensure_ascii=False)

        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        now = datetime.now().isoformat()
        if not item.get("created_at"):
            item["created_at"] = now
        if not item.get("last_modified"):
            item["last_modified"] = now

        return item

    def _update_record(self, cursor, table_name: str, local_id: int, data: dict):
        """ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ù…Ø­Ù„ÙŠ"""
        if not data:
            return

        set_clause = ", ".join([f"{k}=?" for k in data.keys()])
        values = list(data.values()) + [local_id]
        cursor.execute(f"UPDATE {table_name} SET {set_clause} WHERE id=?", values)

    def _insert_record(self, cursor, table_name: str, data: dict):
        """Ø¥Ø¯Ø±Ø§Ø¬ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª"""
        if not data:
            return

        # âš¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„Ø¯ÙØ¹Ø§Øª - ÙØ­Øµ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¨Ù€ (project_id + date + amount)
        if table_name == "payments":
            project_id = data.get("project_id")
            date = data.get("date", "")
            amount = data.get("amount", 0)
            date_short = str(date)[:10] if date else ""

            if project_id and amount:
                try:
                    cursor.execute(
                        """SELECT id FROM payments
                           WHERE project_id = ? AND amount = ? AND date LIKE ?""",
                        (project_id, amount, f"{date_short}%"),
                    )
                    existing = cursor.fetchone()
                    if existing:
                        # ØªØ­Ø¯ÙŠØ« Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø¥Ø¯Ø±Ø§Ø¬
                        self._update_record(cursor, table_name, existing[0], data)
                        logger.debug("ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¯ÙØ¹Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©: %s - %s", project_id, amount)
                        return
                except Exception:
                    pass

        columns = ", ".join(data.keys())
        placeholders = ", ".join(["?" for _ in data])

        try:
            cursor.execute(
                f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})", list(data.values())
            )
        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„Ø© UNIQUE constraint - Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¥Ø¯Ø±Ø§Ø¬
            if "UNIQUE constraint" in str(e):
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙˆØªØ­Ø¯ÙŠØ«Ù‡
                unique_field = self.UNIQUE_FIELDS.get(table_name, "name")
                unique_value = data.get(unique_field)
                mongo_id = data.get("_mongo_id")

                if unique_value:
                    try:
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
                        cursor.execute(
                            f"SELECT id FROM {table_name} WHERE {unique_field} = ?", (unique_value,)
                        )
                        row = cursor.fetchone()
                        if row:
                            self._update_record(cursor, table_name, row[0], data)
                            logger.debug("ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙƒØ±Ø±: %s", unique_value)
                            return
                    except Exception:
                        pass

                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¨Ù€ mongo_id
                if mongo_id:
                    try:
                        cursor.execute(
                            f"SELECT id FROM {table_name} WHERE _mongo_id = ?", (mongo_id,)
                        )
                        row = cursor.fetchone()
                        if row:
                            self._update_record(cursor, table_name, row[0], data)
                            return
                    except Exception:
                        pass

                # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¥Ø°Ø§ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡
                logger.debug("ØªØ¬Ø§Ù‡Ù„ Ø³Ø¬Ù„ Ù…ÙƒØ±Ø± ÙÙŠ %s", table_name)
            else:
                raise

    def _push_pending_changes(self):
        """
        Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© Ù„Ù„Ø³Ø­Ø§Ø¨Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø³Ø­Ø¨
        """
        # âš¡ ÙØ­Øµ Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„Ø¥ØºÙ„Ø§Ù‚
        if self._shutdown:
            return

        if not self.is_online:
            return

        if self.repo is None or self.repo.mongo_db is None or self.repo.mongo_client is None:
            logger.debug("ØªÙ… ØªØ®Ø·ÙŠ Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª - MongoDB client ØºÙŠØ± Ù…ØªØ§Ø­")
            return

        logger.info("ğŸ“¤ Ø¬Ø§Ø±ÙŠ Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©...")

        for table in self.TABLES:
            try:
                self._push_table_changes(table)
            except Exception as e:
                logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ %s: %s", table, e)

    def _push_table_changes(self, table_name: str):
        """Ø±ÙØ¹ ØªØºÙŠÙŠØ±Ø§Øª Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯"""
        # âš¡ ÙØ­Øµ Ø§Ù„Ø§ØªØµØ§Ù„ Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… MongoDB
        if self._shutdown:
            return

        if self.repo is None or not self.repo.online:
            return

        if self.repo.mongo_db is None or self.repo.mongo_client is None:
            logger.debug("ØªÙ… ØªØ®Ø·ÙŠ Ø±ÙØ¹ %s - MongoDB client ØºÙŠØ± Ù…ØªØ§Ø­", table_name)
            return

        # âš¡ Ø¥Ù†Ø´Ø§Ø¡ cursor Ø¬Ø¯ÙŠØ¯ Ù„ØªØ¬Ù†Ø¨ Recursive cursor error
        try:
            cursor = self.repo.get_cursor()
        except Exception as e:
            logger.debug("ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ cursor: %s", e)
            return

        conn = self.repo.sqlite_conn
        unique_field = self.UNIQUE_FIELDS.get(table_name, "name")

        try:
            # Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
            cursor.execute(
                f"""
                SELECT * FROM {table_name}
                WHERE sync_status != 'synced' OR sync_status IS NULL
            """
            )
            unsynced = cursor.fetchall()
        except Exception as e:
            logger.debug("ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©: %s", e)
            cursor.close()
            return

        if not unsynced:
            cursor.close()
            return

        try:
            collection = self.repo.mongo_db[table_name]
        except Exception as e:
            if "Cannot use MongoClient after close" in str(e):
                logger.warning("âš ï¸ MongoDB client Ù…ØºÙ„Ù‚ - ØªØ®Ø·ÙŠ Ø±ÙØ¹ %s", table_name)
            cursor.close()
            return

        pushed = 0

        try:
            for row in unsynced:
                row_dict = dict(row)
                local_id = row_dict.get("id")
                mongo_id = row_dict.get("_mongo_id")
                unique_value = row_dict.get(unique_field)
                sync_status = row_dict.get("sync_status")

                if sync_status == "deleted":
                    try:
                        if mongo_id:
                            from bson import ObjectId

                            collection.delete_one({"_id": ObjectId(mongo_id)})
                        elif unique_value:
                            collection.delete_one({unique_field: unique_value})
                        cursor.execute(
                            f"DELETE FROM {table_name} WHERE id = ?",
                            (local_id,),
                        )
                        pushed += 1
                    except Exception as e:
                        logger.error("âŒ ÙØ´Ù„ Ø­Ø°Ù %s/%s: %s", table_name, local_id, e)
                    continue

                cloud_data = self._prepare_data_for_cloud(row_dict)

                try:
                    if mongo_id:
                        from bson import ObjectId

                        collection.update_one({"_id": ObjectId(mongo_id)}, {"$set": cloud_data})
                    else:
                        # âš¡ ÙØ­Øµ Ø§Ù„ØªÙƒØ±Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø¯Ø±Ø§Ø¬ - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„Ø¯ÙØ¹Ø§Øª
                        existing = None

                        if table_name == "payments":
                            # Ø§Ù„Ø¨Ø­Ø« Ø¨Ù€ (project_id + date + amount)
                            project_id = row_dict.get("project_id")
                            date = row_dict.get("date", "")
                            amount = row_dict.get("amount", 0)
                            date_short = str(date)[:10] if date else ""

                            if project_id and amount:
                                existing = collection.find_one(
                                    {
                                        "project_id": project_id,
                                        "amount": amount,
                                        "date": {"$regex": f"^{date_short}"},
                                    }
                                )
                        elif unique_value:
                            existing = collection.find_one({unique_field: unique_value})

                        if existing:
                            # Ø±Ø¨Ø· Ø¨Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
                            mongo_id = str(existing["_id"])
                            collection.update_one({"_id": existing["_id"]}, {"$set": cloud_data})
                        else:
                            # Ø¥Ø¯Ø±Ø§Ø¬ Ø¬Ø¯ÙŠØ¯
                            result = collection.insert_one(cloud_data)
                            mongo_id = str(result.inserted_id)

                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ
                    cursor.execute(
                        f"UPDATE {table_name} SET _mongo_id = ?, sync_status = 'synced' WHERE id = ?",
                        (mongo_id, local_id),
                    )
                    pushed += 1

                except Exception as e:
                    # âš¡ ØªØ¬Ø§Ù‡Ù„ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªÙƒØ±Ø§Ø±
                    if "duplicate key" in str(e).lower() or "E11000" in str(e):
                        logger.debug("ØªØ¬Ø§Ù‡Ù„ Ø³Ø¬Ù„ Ù…ÙƒØ±Ø± ÙÙŠ %s: %s", table_name, e)
                        # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø¹Ù„Ù‰ Ø£ÙŠ Ø­Ø§Ù„
                        cursor.execute(
                            f"UPDATE {table_name} SET sync_status = 'synced' WHERE id = ?",
                            (local_id,),
                        )
                    else:
                        logger.error("âŒ ÙØ´Ù„ Ø±ÙØ¹ %s/%s: %s", table_name, local_id, e)

            try:
                conn.commit()
            except Exception:
                pass

            if pushed > 0:
                logger.info("ğŸ“¤ %s: Ø±ÙØ¹ %s Ø³Ø¬Ù„", table_name, pushed)

        finally:
            # âš¡ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù€ cursor
            try:
                cursor.close()
            except Exception:
                pass

    def _prepare_data_for_cloud(self, data: dict) -> dict:
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø±ÙØ¹ Ù„Ù„Ø³Ø­Ø§Ø¨Ø©"""
        clean = {k: v for k, v in data.items() if k not in ["id", "_mongo_id", "sync_status"]}

        # âš¡ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ logo_data
        # Ø¥Ø°Ø§ ÙƒØ§Ù† logo_data ÙØ§Ø±Øº Ùˆ logo_path ÙØ§Ø±Øº = Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø­Ø°Ù Ø§Ù„ØµÙˆØ±Ø© ØµØ±Ø§Ø­Ø©
        # Ø¥Ø°Ø§ ÙƒØ§Ù† logo_data ÙØ§Ø±Øº Ùˆ logo_path Ù…ÙˆØ¬ÙˆØ¯ = Ù„Ø§ Ù†Ø±ÙŠØ¯ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙÙˆÙ‚ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
        logo_data_value = clean.get("logo_data", None)
        logo_path_value = clean.get("logo_path", None)

        if "logo_data" in clean:
            if logo_data_value:
                # ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø© - Ø±ÙØ¹Ù‡Ø§ Ù„Ù„Ø³Ø­Ø§Ø¨Ø©
                logger.info("ğŸ“· Ø±ÙØ¹ logo_data (%s Ø­Ø±Ù) Ù„Ù„Ø³Ø­Ø§Ø¨Ø©", len(logo_data_value))
            elif not logo_path_value:
                # logo_data ÙØ§Ø±Øº Ùˆ logo_path ÙØ§Ø±Øº = Ø­Ø°Ù ØµØ±ÙŠØ­ Ù„Ù„ØµÙˆØ±Ø©
                clean["logo_data"] = ""  # Ø¥Ø±Ø³Ø§Ù„ Ù‚ÙŠÙ…Ø© ÙØ§Ø±ØºØ© ØµØ±ÙŠØ­Ø© Ù„Ù„Ø­Ø°Ù
                logger.info("ğŸ—‘ï¸ Ø­Ø°Ù logo_data Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø© (Ø­Ø°Ù ØµØ±ÙŠØ­)")
            else:
                # logo_data ÙØ§Ø±Øº Ù„ÙƒÙ† logo_path Ù…ÙˆØ¬ÙˆØ¯ = Ù„Ø§ Ù†Ø±ÙŠØ¯ Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙÙˆÙ‚ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
                del clean["logo_data"]
                logger.debug("ğŸ“· ØªÙ… ØªØ¬Ø§Ù‡Ù„ logo_data Ø§Ù„ÙØ§Ø±Øº (Ù„Ù† ÙŠØªÙ… Ø§Ù„ÙƒØªØ§Ø¨Ø© ÙÙˆÙ‚ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©)")

        if "logo_path" in clean and not clean["logo_path"]:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† logo_path ÙØ§Ø±ØºØŒ Ù†Ø±Ø³Ù„ Ù‚ÙŠÙ…Ø© ÙØ§Ø±ØºØ© ØµØ±ÙŠØ­Ø©
            clean["logo_path"] = ""

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        for field in [
            "created_at",
            "last_modified",
            "date",
            "issue_date",
            "due_date",
            "expiry_date",
            "start_date",
            "end_date",
        ]:
            if field in clean and clean[field]:
                try:
                    if isinstance(clean[field], str):
                        clean[field] = datetime.fromisoformat(clean[field].replace("Z", "+00:00"))
                except (ValueError, TypeError):
                    pass

        # ØªØ­ÙˆÙŠÙ„ JSON strings Ø¥Ù„Ù‰ objects
        for field in ["items", "lines", "data", "milestones"]:
            if field in clean and clean[field]:
                try:
                    if isinstance(clean[field], str):
                        clean[field] = json.loads(clean[field])
                except (json.JSONDecodeError, TypeError):
                    pass

        return clean

    def _sync_users_from_cloud(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø«Ù†Ø§Ø¦ÙŠØ© Ø§Ù„Ø§ØªØ¬Ø§Ù‡ (Ù…Ù† ÙˆØ¥Ù„Ù‰ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©)"""
        try:
            # âš¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… cursor Ù…Ù†ÙØµÙ„ Ù„ØªØ¬Ù†Ø¨ Recursive cursor error
            cursor = self.repo.get_cursor()
            conn = self.repo.sqlite_conn

            try:
                # === 1. Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø­Ù„ÙŠÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯/Ø§Ù„Ù…Ø¹Ø¯Ù„ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„Ø³Ø­Ø§Ø¨Ø© ===
                logger.info("ğŸ“¤ Ø¬Ø§Ø±ÙŠ Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø­Ù„ÙŠÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©...")
                cursor.execute(
                    """
                    SELECT * FROM users
                    WHERE sync_status IN ('new_offline', 'modified_offline', 'pending')
                       OR _mongo_id IS NULL
                """
                )
                local_pending = cursor.fetchall()

                uploaded_count = 0
                for row in local_pending:
                    user_data = dict(row)
                    username = user_data.get("username")
                    local_id = user_data.get("id")

                    existing_cloud = self.repo.mongo_db.users.find_one({"username": username})

                    if existing_cloud:
                        mongo_id = str(existing_cloud["_id"])
                        update_data = {
                            "full_name": user_data.get("full_name"),
                            "email": user_data.get("email"),
                            "role": user_data.get("role"),
                            "is_active": bool(user_data.get("is_active", 1)),
                            "last_modified": datetime.now(),
                        }
                        if user_data.get("password_hash"):
                            update_data["password_hash"] = user_data["password_hash"]

                        self.repo.mongo_db.users.update_one(
                            {"_id": existing_cloud["_id"]}, {"$set": update_data}
                        )
                        cursor.execute(
                            "UPDATE users SET _mongo_id=?, sync_status='synced' WHERE id=?",
                            (mongo_id, local_id),
                        )
                        uploaded_count += 1
                    else:
                        new_user = {
                            "username": username,
                            "password_hash": user_data.get("password_hash"),
                            "full_name": user_data.get("full_name"),
                            "email": user_data.get("email"),
                            "role": user_data.get("role", "sales"),
                            "is_active": bool(user_data.get("is_active", 1)),
                            "created_at": datetime.now(),
                            "last_modified": datetime.now(),
                        }
                        result = self.repo.mongo_db.users.insert_one(new_user)
                        mongo_id = str(result.inserted_id)
                        cursor.execute(
                            "UPDATE users SET _mongo_id=?, sync_status='synced' WHERE id=?",
                            (mongo_id, local_id),
                        )
                        uploaded_count += 1

                if uploaded_count > 0:
                    conn.commit()
                    logger.info("ğŸ“¤ ØªÙ… Ø±ÙØ¹ %s Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø³Ø­Ø§Ø¨Ø©", uploaded_count)

                # === 2. ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø© ===
                logger.info("ğŸ“¥ Ø¬Ø§Ø±ÙŠ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©...")
                cloud_users = list(self.repo.mongo_db.users.find())
                if not cloud_users:
                    return

                downloaded_count = 0
                for u in cloud_users:
                    mongo_id = str(u["_id"])
                    username = u.get("username")

                    for field in ["created_at", "last_modified", "last_login"]:
                        if field in u and hasattr(u[field], "isoformat"):
                            u[field] = u[field].isoformat()

                    cursor.execute(
                        "SELECT id, sync_status FROM users WHERE _mongo_id = ? OR username = ?",
                        (mongo_id, username),
                    )
                    exists = cursor.fetchone()

                    if exists:
                        if exists[1] not in ("modified_offline", "new_offline"):
                            cursor.execute(
                                """
                                UPDATE users SET
                                    full_name=?, email=?, role=?, is_active=?,
                                    password_hash=?, _mongo_id=?, sync_status='synced',
                                    last_modified=?
                                WHERE id=?
                            """,
                                (
                                    u.get("full_name"),
                                    u.get("email"),
                                    u.get("role"),
                                    u.get("is_active", 1),
                                    u.get("password_hash"),
                                    mongo_id,
                                    u.get("last_modified", datetime.now().isoformat()),
                                    exists[0],
                                ),
                            )
                            downloaded_count += 1
                    else:
                        cursor.execute(
                            """
                            INSERT INTO users (
                                _mongo_id, username, full_name, email, role,
                                password_hash, is_active, sync_status, created_at, last_modified
                            ) VALUES (?, ?, ?, ?, ?, ?, ?, 'synced', ?, ?)
                        """,
                            (
                                mongo_id,
                                username,
                                u.get("full_name"),
                                u.get("email"),
                                u.get("role"),
                                u.get("password_hash"),
                                u.get("is_active", 1),
                                u.get("created_at", datetime.now().isoformat()),
                                u.get("last_modified", datetime.now().isoformat()),
                            ),
                        )
                        downloaded_count += 1

                conn.commit()
                logger.info(
                    "âœ… ØªÙ… Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† (Ø±ÙØ¹: %sØŒ ØªÙ†Ø²ÙŠÙ„: %s)",
                    uploaded_count,
                    downloaded_count,
                )

            finally:
                cursor.close()

        except Exception as e:
            logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†: %s", e)

    # ==========================================
    # Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
    # ==========================================

    def remove_duplicates(self, table_name: str | None = None) -> dict[str, int]:
        """
        Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        ÙŠØ­ØªÙØ¸ Ø¨Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø£Ù‚Ø¯Ù… (Ø£Ù‚Ù„ id) ÙˆÙŠØ­Ø°Ù Ø§Ù„Ø¨Ø§Ù‚ÙŠ
        """
        tables = [table_name] if table_name else self.TABLES
        results = {}

        # âš¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… cursor Ù…Ù†ÙØµÙ„ Ù„ØªØ¬Ù†Ø¨ Recursive cursor error
        cursor = self.repo.get_cursor()
        conn = self.repo.sqlite_conn

        try:
            for table in tables:
                try:
                    unique_field = self.UNIQUE_FIELDS.get(table, "name")

                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
                    cursor.execute(
                        f"""
                        SELECT {unique_field}, COUNT(*) as cnt, MIN(id) as keep_id
                        FROM {table}
                        WHERE {unique_field} IS NOT NULL
                        GROUP BY {unique_field}
                        HAVING cnt > 1
                    """
                    )
                    duplicates = cursor.fetchall()

                    deleted = 0
                    for dup in duplicates:
                        unique_value = dup[0]
                        keep_id = dup[2]

                        # Ø­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª (Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ø£Ù‚Ø¯Ù…)
                        cursor.execute(
                            f"""
                            DELETE FROM {table}
                            WHERE {unique_field} = ? AND id != ?
                        """,
                            (unique_value, keep_id),
                        )
                        deleted += cursor.rowcount

                    conn.commit()
                    results[table] = deleted

                    if deleted > 0:
                        logger.info("ğŸ—‘ï¸ %s: Ø­Ø°Ù %s Ø³Ø¬Ù„ Ù…ÙƒØ±Ø±", table, deleted)

                except Exception as e:
                    logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø²Ø§Ù„Ø© ØªÙƒØ±Ø§Ø±Ø§Øª %s: %s", table, e)
                    results[table] = 0
        finally:
            cursor.close()

        return results

    def force_full_resync(self) -> dict[str, Any]:
        """
        Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø²Ø§Ù…Ù†Ø© ÙƒØ§Ù…Ù„Ø© Ù‚Ø³Ø±ÙŠØ©
        1. Ø­Ø°Ù ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        2. Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
        """
        if not self.is_online:
            return {"success": False, "reason": "offline"}

        logger.warning("âš ï¸ Ø¨Ø¯Ø¡ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø§Ù„Ù‚Ø³Ø±ÙŠØ©...")

        # âš¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… cursor Ù…Ù†ÙØµÙ„ Ù„ØªØ¬Ù†Ø¨ Recursive cursor error
        cursor = self.repo.get_cursor()
        conn = self.repo.sqlite_conn

        try:
            # Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© (Ù…Ø§ Ø¹Ø¯Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†)
            for table in self.TABLES:
                try:
                    cursor.execute(f"DELETE FROM {table}")
                    logger.info("ğŸ—‘ï¸ ØªÙ… Ù…Ø³Ø­ %s", table)
                except Exception as e:
                    logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ %s: %s", table, e)

            conn.commit()
        finally:
            cursor.close()

        # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
        return self.full_sync_from_cloud()

    def get_sync_status(self) -> dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©"""
        # âš¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… cursor Ù…Ù†ÙØµÙ„ Ù„ØªØ¬Ù†Ø¨ Recursive cursor error
        cursor = self.repo.get_cursor()
        status = {"is_online": self.is_online, "is_syncing": self._is_syncing, "tables": {}}

        try:
            for table in self.TABLES:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    total = cursor.fetchone()[0]

                    cursor.execute(
                        f"""
                        SELECT COUNT(*) FROM {table}
                        WHERE sync_status != 'synced' OR sync_status IS NULL
                    """
                    )
                    pending = cursor.fetchone()[0]

                    status["tables"][table] = {
                        "total": total,
                        "pending": pending,
                        "synced": total - pending,
                    }
                except Exception:
                    status["tables"][table] = {"total": 0, "pending": 0, "synced": 0}
        finally:
            cursor.close()

        return status

    def remove_cloud_duplicates(self) -> dict[str, int]:
        """
        Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ù† MongoDB
        ÙŠØ­ØªÙØ¸ Ø¨Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ø£Ù‚Ø¯Ù… (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ created_at)
        """
        if not self.is_online:
            return {}

        results = {}
        logger.info("ğŸ§¹ Ø¬Ø§Ø±ÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©...")

        for table in self.TABLES:
            try:
                deleted = self._remove_cloud_table_duplicates(table)
                results[table] = deleted
                if deleted > 0:
                    logger.info("ğŸ—‘ï¸ %s: Ø­Ø°Ù %s Ø³Ø¬Ù„ Ù…ÙƒØ±Ø± Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©", table, deleted)
            except Exception as e:
                logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ %s Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©: %s", table, e)
                results[table] = 0

        return results

    def _remove_cloud_table_duplicates(self, table_name: str) -> int:
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ù† Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ ÙÙŠ MongoDB"""
        unique_field = self.UNIQUE_FIELDS.get(table_name, "name")
        collection = self.repo.mongo_db[table_name]

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… aggregation
        pipeline = [
            {
                "$group": {
                    "_id": f"${unique_field}",
                    "count": {"$sum": 1},
                    "docs": {"$push": {"_id": "$_id", "created_at": "$created_at"}},
                }
            },
            {"$match": {"count": {"$gt": 1}}},
        ]

        duplicates = list(collection.aggregate(pipeline))
        deleted = 0

        for dup in duplicates:
            docs = dup["docs"]
            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ created_at (Ø§Ù„Ø£Ù‚Ø¯Ù… Ø£ÙˆÙ„Ø§Ù‹)
            docs.sort(key=lambda x: x.get("created_at") or datetime.min)

            # Ø­Ø°Ù ÙƒÙ„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ø§ Ø¹Ø¯Ø§ Ø§Ù„Ø£ÙˆÙ„
            for doc in docs[1:]:
                collection.delete_one({"_id": doc["_id"]})
                deleted += 1

        return deleted

    def full_cleanup_and_sync(self) -> dict[str, Any]:
        """
        ØªÙ†Ø¸ÙŠÙ ÙƒØ§Ù…Ù„ ÙˆÙ…Ø²Ø§Ù…Ù†Ø©:
        1. ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ù…Ù† MongoDB
        2. ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        3. Ù…Ø²Ø§Ù…Ù†Ø© ÙƒØ§Ù…Ù„Ø©
        """
        results = {"cloud_cleanup": {}, "local_cleanup": {}, "sync": {}}

        if self.is_online:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
            logger.info("â˜ï¸ Ø¬Ø§Ø±ÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø­Ø§Ø¨Ø©...")
            results["cloud_cleanup"] = self.remove_cloud_duplicates()

        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø­Ù„ÙŠ
        logger.info("ğŸ’¾ Ø¬Ø§Ø±ÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©...")
        results["local_cleanup"] = self.remove_duplicates()

        # Ù…Ø²Ø§Ù…Ù†Ø©
        if self.is_online:
            logger.info("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©...")
            results["sync"] = self.full_sync_from_cloud()

        return results

    # ==========================================
    # âš¡ Bidirectional Delta Sync - NEW
    # ==========================================

    def _load_watermarks(self):
        """ØªØ­Ù…ÙŠÙ„ Watermarks Ù…Ù† Ù…Ù„Ù Ù…Ø­Ù„ÙŠ"""
        try:
            from pathlib import Path

            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if hasattr(self.repo, "sqlite_conn") and self.repo.sqlite_conn:
                db_path = (
                    self.repo.sqlite_conn.database
                    if hasattr(self.repo.sqlite_conn, "database")
                    else None
                )
                if db_path:
                    watermark_file = Path(db_path).parent / "sync_watermarks.json"
                    if watermark_file.exists():
                        with open(watermark_file, encoding="utf-8") as f:
                            self._watermarks = json.load(f)
                        logger.info("ğŸ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ Watermarks: %s Ø¬Ø¯Ø§ÙˆÙ„", len(self._watermarks))
                        return
            self._watermarks = {}
        except Exception as e:
            logger.debug("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Watermarks: %s", e)
            self._watermarks = {}

    def _save_watermarks(self):
        """Ø­ÙØ¸ Watermarks Ø¥Ù„Ù‰ Ù…Ù„Ù Ù…Ø­Ù„ÙŠ"""
        try:
            from pathlib import Path

            if hasattr(self.repo, "sqlite_conn") and self.repo.sqlite_conn:
                db_path = (
                    self.repo.sqlite_conn.database
                    if hasattr(self.repo.sqlite_conn, "database")
                    else None
                )
                if db_path:
                    watermark_file = Path(db_path).parent / "sync_watermarks.json"
                    with open(watermark_file, "w", encoding="utf-8") as f:
                        json.dump(self._watermarks, f)
                    logger.debug("ğŸ“ ØªÙ… Ø­ÙØ¸ Watermarks")
        except Exception as e:
            logger.debug("ÙØ´Ù„ Ø­ÙØ¸ Watermarks: %s", e)

    def push_local_changes(self) -> dict[str, Any]:
        """
        âš¡ Push all locally modified records (dirty_flag = 1) to MongoDB
        Returns: dict with counts of pushed records and any errors
        """
        if not self.is_online:
            return {"success": False, "reason": "offline"}

        if self._shutdown:
            return {"success": False, "reason": "shutdown"}

        results = {"success": True, "pushed": 0, "deleted": 0, "errors": 0}

        try:
            cursor = self.repo.get_cursor()

            for table in self.TABLES:
                try:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    cursor.execute(
                        "SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table,)
                    )
                    if not cursor.fetchone():
                        continue

                    # Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‘Ù…Ø© Ø¨Ù€ dirty_flag = 1
                    cursor.execute(
                        f"""
                        SELECT * FROM {table}
                        WHERE dirty_flag = 1 OR dirty_flag IS NULL AND sync_status = 'new_offline'
                    """
                    )
                    dirty_records = cursor.fetchall()

                    if not dirty_records:
                        continue

                    columns = [desc[0] for desc in cursor.description]
                    collection = self.repo.mongo_db[table]

                    for row in dirty_records:
                        try:
                            record = dict(zip(columns, row, strict=False))
                            local_id = record.get("id")
                            mongo_id = record.get("_mongo_id")
                            is_deleted = record.get("is_deleted", 0)

                            if is_deleted:
                                # Soft Delete: Ø­Ø°Ù Ù…Ù† MongoDB Ø«Ù… Ù…Ø­Ù„ÙŠØ§Ù‹
                                if mongo_id:
                                    try:
                                        from bson import ObjectId

                                        # ØªØ­Ø¯ÙŠØ« ÙÙŠ MongoDB Ø¨Ù€ is_deleted = True
                                        collection.update_one(
                                            {"_id": ObjectId(mongo_id)},
                                            {
                                                "$set": {
                                                    "is_deleted": True,
                                                    "last_modified": datetime.now().isoformat(),
                                                }
                                            },
                                        )
                                    except Exception as del_err:
                                        logger.debug("ØªØ¬Ø§Ù‡Ù„ Ø®Ø·Ø£ Ø­Ø°Ù Ù…Ù† MongoDB: %s", del_err)

                                # Ø­Ø°Ù Ù…Ø­Ù„ÙŠØ§Ù‹ (Hard Delete Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©)
                                cursor.execute(f"DELETE FROM {table} WHERE id = ?", (local_id,))
                                results["deleted"] += 1
                            else:
                                # Upsert Ø¥Ù„Ù‰ MongoDB
                                clean_record = {
                                    k: v
                                    for k, v in record.items()
                                    if k not in ["id", "sync_status", "dirty_flag", "is_deleted"]
                                }
                                clean_record["last_modified"] = datetime.now().isoformat()

                                if mongo_id:
                                    from bson import ObjectId

                                    collection.update_one(
                                        {"_id": ObjectId(mongo_id)},
                                        {"$set": clean_record},
                                        upsert=True,
                                    )
                                else:
                                    result = collection.insert_one(clean_record)
                                    mongo_id = str(result.inserted_id)
                                    cursor.execute(
                                        f"UPDATE {table} SET _mongo_id = ? WHERE id = ?",
                                        (mongo_id, local_id),
                                    )

                                # ØªØ­Ø¯ÙŠØ« dirty_flag Ùˆ sync_status
                                cursor.execute(
                                    f"""
                                    UPDATE {table}
                                    SET dirty_flag = 0, sync_status = 'synced'
                                    WHERE id = ?
                                """,
                                    (local_id,),
                                )
                                results["pushed"] += 1

                        except Exception as e:
                            logger.debug("Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø³Ø¬Ù„ Ù…Ù† %s: %s", table, e)
                            results["errors"] += 1

                    self.repo.sqlite_conn.commit()

                except Exception as e:
                    logger.debug("Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø¬Ø¯ÙˆÙ„ %s: %s", table, e)

            cursor.close()

            if results["pushed"] > 0 or results["deleted"] > 0:
                logger.info("â¬†ï¸ Push: %s Ø±ÙØ¹, %s Ø­Ø°Ù", results["pushed"], results["deleted"])

        except Exception as e:
            logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ push_local_changes: %s", e)
            results["success"] = False
            results["error"] = str(e)

        return results

    def pull_remote_changes(self) -> dict[str, Any]:
        """
        âš¡ Pull changes from MongoDB since last sync (watermark-based delta sync)
        Only pulls records where last_modified > watermark
        Returns: dict with counts of pulled/deleted records
        """
        if not self.is_online:
            return {"success": False, "reason": "offline"}

        if self._shutdown:
            return {"success": False, "reason": "shutdown"}

        if self._is_syncing:
            return {"success": False, "reason": "already_syncing"}

        results = {"success": True, "pulled": 0, "deleted": 0, "errors": 0}

        try:
            cursor = self.repo.get_cursor()

            for table in self.TABLES:
                try:
                    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Watermark Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    watermark = self._watermarks.get(table, "1970-01-01T00:00:00")

                    # Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ù† MongoDB Ø§Ù„Ù…Ø­Ø¯Ù‘Ø«Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ù€ watermark
                    collection = self.repo.mongo_db[table]
                    query = {"last_modified": {"$gt": watermark}}
                    remote_records = list(collection.find(query))

                    if not remote_records:
                        continue

                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ø­Ù„ÙŠØ§Ù‹
                    cursor.execute(
                        "SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table,)
                    )
                    if not cursor.fetchone():
                        continue

                    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    cursor.execute(f"PRAGMA table_info({table})")
                    table_columns = {row[1] for row in cursor.fetchall()}

                    max_timestamp = watermark

                    for remote in remote_records:
                        try:
                            mongo_id = str(remote["_id"])
                            is_deleted = remote.get("is_deleted", False)
                            last_modified = remote.get("last_modified", "")

                            # ØªØ­Ø¯ÙŠØ« max_timestamp
                            if last_modified and last_modified > max_timestamp:
                                max_timestamp = last_modified

                            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ
                            cursor.execute(
                                f"SELECT id FROM {table} WHERE _mongo_id = ?", (mongo_id,)
                            )
                            local_row = cursor.fetchone()

                            if is_deleted:
                                # Ø­Ø°Ù Ù…Ù† MongoDB -> Ø­Ø°Ù Ù…Ø­Ù„ÙŠØ§Ù‹
                                if local_row:
                                    cursor.execute(
                                        f"DELETE FROM {table} WHERE id = ?", (local_row[0],)
                                    )
                                    results["deleted"] += 1
                            else:
                                # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                                item_data = self._prepare_cloud_data(remote)
                                item_data["_mongo_id"] = mongo_id
                                item_data["sync_status"] = "synced"
                                item_data["dirty_flag"] = 0
                                item_data["is_deleted"] = 0

                                # ØªØµÙÙŠØ© Ø§Ù„Ø­Ù‚ÙˆÙ„
                                filtered = {
                                    k: v for k, v in item_data.items() if k in table_columns
                                }

                                if local_row:
                                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
                                    set_clause = ", ".join([f"{k} = ?" for k in filtered.keys()])
                                    values = list(filtered.values()) + [local_row[0]]
                                    cursor.execute(
                                        f"UPDATE {table} SET {set_clause} WHERE id = ?", values
                                    )
                                else:
                                    # Ø¥Ø¯Ø±Ø§Ø¬ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯
                                    cols = ", ".join(filtered.keys())
                                    placeholders = ", ".join(["?" for _ in filtered])
                                    cursor.execute(
                                        f"INSERT INTO {table} ({cols}) VALUES ({placeholders})",
                                        list(filtered.values()),
                                    )
                                results["pulled"] += 1

                        except Exception as e:
                            logger.debug("Ø®Ø·Ø£ ÙÙŠ Ø³Ø­Ø¨ Ø³Ø¬Ù„ Ù…Ù† %s: %s", table, e)
                            results["errors"] += 1

                    if remote_records:
                        # âš¡ CRITICAL: Update watermark based on the LATEST record found
                        try:
                            latest_ts = max(r.get("last_modified", "") for r in remote_records)
                            current_watermark = self._watermarks.get(table, "")

                            if latest_ts and latest_ts > current_watermark:
                                self._watermarks[table] = latest_ts
                                self._save_watermarks()  # âš¡ Save immediately
                                logger.info("ğŸ“ Watermark updated for %s: %s", table, latest_ts)
                        except Exception as wm_err:
                            logger.error("âŒ Failed to update watermark for %s: %s", table, wm_err)

                    self.repo.sqlite_conn.commit()

                except Exception as e:
                    logger.debug("Ø®Ø·Ø£ ÙÙŠ Ø³Ø­Ø¨ Ø¬Ø¯ÙˆÙ„ %s: %s", table, e)

            cursor.close()

            # Ø­ÙØ¸ Ø§Ù„Ù€ watermarks
            self._save_watermarks()

            if results["pulled"] > 0 or results["deleted"] > 0:
                logger.info("â¬‡ï¸ Pull: %s Ø³Ø­Ø¨, %s Ø­Ø°Ù", results["pulled"], results["deleted"])
                # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
                try:
                    self.data_synced.emit()
                except RuntimeError:
                    pass  # Qt object deleted

        except Exception as e:
            logger.error("âŒ Ø®Ø·Ø£ ÙÙŠ pull_remote_changes: %s", e)
            results["success"] = False
            results["error"] = str(e)

        return results

    def force_pull(self, table: str = None):
        """
        âš¡ Force immediate pull (for screen open events)
        Pushes local changes first, then pulls remote changes
        """
        if self._shutdown or self._is_syncing or not self.is_online:
            return

        def pull_thread():
            if self._shutdown:
                return
            try:
                # Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
                self.push_local_changes()
                # Ø³Ø­Ø¨ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠØ±ÙØ±
                self.pull_remote_changes()
            except Exception as e:
                logger.debug("Ø®Ø·Ø£ ÙÙŠ force_pull: %s", e)

        threading.Thread(target=pull_thread, daemon=True).start()

    def start_delta_sync(self, interval_seconds: int = 60):
        """
        âš¡ Ø¨Ø¯Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙØ§Ø¶Ù„ÙŠØ© (Delta Sync)
        ÙŠÙ‚ÙˆÙ… Ø¨Ø³Ø­Ø¨ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙƒÙ„ ÙØªØ±Ø© Ù…Ø­Ø¯Ø¯Ø©
        """
        if self._delta_pull_timer:
            self._delta_pull_timer.stop()

        interval_ms = interval_seconds * 1000

        def periodic_delta_sync():
            if self._shutdown or self._is_syncing or not self.is_online:
                return

            def sync_thread():
                try:
                    self.push_local_changes()
                    self.pull_remote_changes()
                except Exception as e:
                    logger.debug("Ø®Ø·Ø£ ÙÙŠ periodic delta sync: %s", e)

            threading.Thread(target=sync_thread, daemon=True).start()

        self._delta_pull_timer = QTimer(self)
        self._delta_pull_timer.timeout.connect(periodic_delta_sync)
        self._delta_pull_timer.start(interval_ms)

        logger.info("â° Ø¨Ø¯Ø¡ Delta Sync ÙƒÙ„ %s Ø«Ø§Ù†ÙŠØ©", interval_seconds)


def create_unified_sync_manager(repository) -> UnifiedSyncManagerV3:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ù…Ø²Ø§Ù…Ù†Ø© Ù…ÙˆØ­Ø¯"""
    return UnifiedSyncManagerV3(repository)
