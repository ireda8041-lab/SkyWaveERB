"""
ğŸš€ Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø«Ø§Ù„Ø«
=====================================
Ø­Ù„ Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©:
- Ù…Ù†Ø¹ Ø§Ø®ØªÙØ§Ø¡ Ø§Ù„Ù…ÙˆØ¸ÙÙŠÙ†
- Ø¶Ù…Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- Ù…Ø²Ø§Ù…Ù†Ø© Ø°ÙƒÙŠØ© ÙˆØ¢Ù…Ù†Ø©
- Ø­Ù…Ø§ÙŠØ© Ù…Ù† ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
"""

import json
import sqlite3
import threading
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Callable
import os

from PyQt6.QtCore import QObject, QTimer, pyqtSignal

from core.logger import get_logger

logger = get_logger(__name__)


class SyncManagerV3(QObject):
    """
    ğŸš€ Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø«Ø§Ù„Ø«
    ÙŠØ¶Ù…Ù† Ø¹Ø¯Ù… ÙÙ‚Ø¯Ø§Ù† Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ…Ø²Ø§Ù…Ù†Ø© Ø¢Ù…Ù†Ø© 100%
    """
    
    # Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
    sync_started = pyqtSignal()
    sync_progress = pyqtSignal(str, int, int)  # table, current, total
    sync_completed = pyqtSignal(dict)
    sync_error = pyqtSignal(str)
    connection_changed = pyqtSignal(bool)
    data_conflict = pyqtSignal(str, dict, dict)  # table, local, remote
    
    # Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    SYNC_TABLES = [
        'clients', 'projects', 'services', 'accounts', 'employees',
        'invoices', 'payments', 'expenses', 'journal_entries',
        'quotations', 'currencies', 'notifications', 'tasks'
    ]
    
    # Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø­Ù…ÙŠØ© (Ù„Ø§ ØªÙØ­Ø°Ù Ø£Ø¨Ø¯Ø§Ù‹)
    PROTECTED_TABLES = ['users', 'settings', 'user_preferences']
    
    # Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ÙØ±ÙŠØ¯Ø©
    UNIQUE_FIELDS = {
        'clients': 'name',
        'employees': 'employee_id',
        'projects': 'name',
        'services': 'name',
        'accounts': 'code',
        'users': 'username',
        'tasks': 'id',
        'invoices': 'invoice_number',
        'quotations': 'quote_number',
        'currencies': 'code'
    }
    
    def __init__(self, repository, parent=None):
        super().__init__(parent)
        self.repo = repository
        self._lock = threading.RLock()
        self._is_syncing = False
        self._sync_stats = {}
        self._conflict_resolution = 'local_wins'  # local_wins, remote_wins, merge
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        self._init_sync_tables()
        
        logger.info("ğŸš€ ØªÙ… ØªÙ‡ÙŠØ¦Ø© SyncManagerV3")
    
    def _init_sync_tables(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ù…Ø²Ø§Ù…Ù†Ø©"""
        try:
            cursor = self.repo.sqlite_cursor
            
            # Ø¬Ø¯ÙˆÙ„ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø°ÙˆÙØ© (Ø³Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ù„Ø§Øª)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS deleted_records (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    table_name TEXT NOT NULL,
                    record_id INTEGER NOT NULL,
                    record_data TEXT NOT NULL,
                    deleted_at TEXT NOT NULL,
                    deleted_by TEXT,
                    can_restore INTEGER DEFAULT 1
                )
            """)
            
            # Ø¬Ø¯ÙˆÙ„ ØªØªØ¨Ø¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS change_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    table_name TEXT NOT NULL,
                    record_id INTEGER NOT NULL,
                    operation TEXT NOT NULL,
                    old_data TEXT,
                    new_data TEXT,
                    changed_at TEXT NOT NULL,
                    changed_by TEXT,
                    sync_status TEXT DEFAULT 'pending'
                )
            """)
            
            # Ø¬Ø¯ÙˆÙ„ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS sync_conflicts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    table_name TEXT NOT NULL,
                    record_id INTEGER NOT NULL,
                    local_data TEXT NOT NULL,
                    remote_data TEXT NOT NULL,
                    resolution TEXT,
                    resolved_at TEXT,
                    created_at TEXT NOT NULL
                )
            """)
            
            # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS sync_backups (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    backup_name TEXT NOT NULL,
                    backup_data TEXT NOT NULL,
                    created_at TEXT NOT NULL,
                    restore_point INTEGER DEFAULT 0
                )
            """)
            
            self.repo.sqlite_conn.commit()
            logger.info("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©: {e}")
    
    @property
    def is_online(self) -> bool:
        """Ø­Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„"""
        return self.repo.online if self.repo else False
    
    @property
    def is_syncing(self) -> bool:
        """Ù‡Ù„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø§Ø±ÙŠØ©ØŸ"""
        return self._is_syncing
    
    def create_backup_point(self, name: str = None) -> bool:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù‚Ø·Ø© Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©"""
        try:
            if not name:
                name = f"auto_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            cursor = self.repo.sqlite_cursor
            backup_data = {}
            
            # Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©
            for table in self.SYNC_TABLES + self.PROTECTED_TABLES:
                try:
                    cursor.execute(f"SELECT * FROM {table}")
                    rows = cursor.fetchall()
                    
                    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³
                    cursor.execute(f"PRAGMA table_info({table})")
                    columns = [col[1] for col in cursor.fetchall()]
                    
                    backup_data[table] = [
                        dict(zip(columns, row)) for row in rows
                    ]
                except Exception as e:
                    logger.warning(f"ØªØ¹Ø°Ø± Ù†Ø³Ø® Ø¬Ø¯ÙˆÙ„ {table}: {e}")
            
            # Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            cursor.execute("""
                INSERT INTO sync_backups (backup_name, backup_data, created_at, restore_point)
                VALUES (?, ?, ?, 1)
            """, (
                name,
                json.dumps(backup_data, ensure_ascii=False, default=str),
                datetime.now().isoformat()
            ))
            
            # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 5 Ù†Ø³Ø® ÙÙ‚Ø·
            cursor.execute("""
                DELETE FROM sync_backups 
                WHERE id NOT IN (
                    SELECT id FROM sync_backups 
                    ORDER BY created_at DESC 
                    LIMIT 5
                )
            """)
            
            self.repo.sqlite_conn.commit()
            logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù‚Ø·Ø© Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù‚Ø·Ø© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {e}")
            return False
    
    def safe_sync_all(self, progress_callback: Callable = None) -> Dict[str, Any]:
        """
        Ù…Ø²Ø§Ù…Ù†Ø© Ø¢Ù…Ù†Ø© Ø´Ø§Ù…Ù„Ø© Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ù…Ù† ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        if not self.is_online:
            return {'success': False, 'error': 'ØºÙŠØ± Ù…ØªØµÙ„ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª'}
        
        if self._is_syncing:
            return {'success': False, 'error': 'Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø§Ø±ÙŠØ© Ø¨Ø§Ù„ÙØ¹Ù„'}
        
        self._is_syncing = True
        self.sync_started.emit()
        
        results = {
            'success': True,
            'backup_created': False,
            'tables_synced': {},
            'conflicts_found': 0,
            'errors': []
        }
        
        try:
            with self._lock:
                # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù‚Ø·Ø© Ø§Ø³ØªØ¹Ø§Ø¯Ø©
                backup_name = f"pre_sync_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                results['backup_created'] = self.create_backup_point(backup_name)
                
                # 2. Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹ (Ù…Ø­Ù…ÙŠØ©)
                self._sync_protected_users()
                
                # 3. Ù…Ø²Ø§Ù…Ù†Ø© ÙƒÙ„ Ø¬Ø¯ÙˆÙ„ Ø¨Ø£Ù…Ø§Ù†
                total_tables = len(self.SYNC_TABLES)
                for i, table in enumerate(self.SYNC_TABLES):
                    try:
                        if progress_callback:
                            progress_callback(f"Ù…Ø²Ø§Ù…Ù†Ø© {table}...", i + 1, total_tables)
                        self.sync_progress.emit(table, i + 1, total_tables)
                        
                        logger.info(f"ğŸ”„ Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø¯ÙˆÙ„: {table} ({i+1}/{total_tables})")
                        
                        # Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„
                        table_result = self._safe_sync_table(table)
                        results['tables_synced'][table] = table_result
                        results['conflicts_found'] += table_result.get('conflicts', 0)
                        
                        logger.info(f"âœ… ØªÙ… Ù…Ø²Ø§Ù…Ù†Ø© {table}: {table_result.get('synced', 0)} Ø³Ø¬Ù„")
                        
                    except Exception as e:
                        error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© {table}: {e}"
                        logger.error(error_msg)
                        results['errors'].append(error_msg)
                        import traceback
                        traceback.print_exc()
                
                # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ§Øª
                total_synced = sum(
                    table_result.get('synced', 0) + table_result.get('updated', 0)
                    for table_result in results['tables_synced'].values()
                )
                results['total_synced'] = total_synced
                
                # 5. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                if results['errors']:
                    results['success'] = len(results['errors']) < len(self.SYNC_TABLES) / 2
                
                logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¢Ù…Ù†Ø©: {len(results['tables_synced'])} Ø¬Ø¯ÙˆÙ„ØŒ {total_synced} Ø³Ø¬Ù„")
                self.sync_completed.emit(results)
                
        except Exception as e:
            error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¢Ù…Ù†Ø©: {e}"
            logger.error(error_msg)
            results['success'] = False
            results['errors'].append(error_msg)
            self.sync_error.emit(error_msg)
        
        finally:
            self._is_syncing = False
        
        return results
    
    def _sync_protected_users(self):
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ø®Ø§ØµØ©"""
        try:
            cursor = self.repo.sqlite_cursor
            
            # Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
            cloud_users = list(self.repo.mongo_db.users.find())
            
            # Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø­Ù„ÙŠÙŠÙ†
            cursor.execute("SELECT * FROM users")
            local_users = cursor.fetchall()
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
            cursor.execute("PRAGMA table_info(users)")
            columns = [col[1] for col in cursor.fetchall()]
            local_users_dict = {
                row[columns.index('username')]: dict(zip(columns, row))
                for row in local_users
            }
            
            # Ù…Ø²Ø§Ù…Ù†Ø© Ø¨Ø¯ÙˆÙ† Ø­Ø°Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø­Ù„ÙŠÙŠÙ†
            for cloud_user in cloud_users:
                username = cloud_user.get('username')
                if not username:
                    continue
                
                # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                user_data = self._prepare_cloud_data_for_local(cloud_user)
                user_data['_mongo_id'] = str(cloud_user['_id'])
                user_data['sync_status'] = 'synced'
                
                if username in local_users_dict:
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ (Ø¨Ø­Ø°Ø±)
                    local_user = local_users_dict[username]
                    
                    # Ù„Ø§ Ù†Ø­Ø¯Ø« ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø®ØªÙ„ÙØ© Ù…Ø­Ù„ÙŠØ§Ù‹
                    if local_user.get('password_hash') != user_data.get('password_hash'):
                        user_data.pop('password_hash', None)
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ÙÙ‚Ø·
                    update_fields = ['full_name', 'email', 'role', '_mongo_id', 'sync_status']
                    set_clause = ', '.join([f"{field}=?" for field in update_fields])
                    values = [user_data.get(field) for field in update_fields] + [local_user['id']]
                    
                    cursor.execute(f"UPDATE users SET {set_clause} WHERE id=?", values)
                else:
                    # Ø¥Ø¶Ø§ÙØ© Ù…Ø³ØªØ®Ø¯Ù… Ø¬Ø¯ÙŠØ¯
                    filtered_data = {k: v for k, v in user_data.items() 
                                   if k in columns and k != 'id'}
                    
                    if filtered_data:
                        cols = ', '.join(filtered_data.keys())
                        placeholders = ', '.join(['?' for _ in filtered_data])
                        cursor.execute(
                            f"INSERT INTO users ({cols}) VALUES ({placeholders})",
                            list(filtered_data.values())
                        )
            
            self.repo.sqlite_conn.commit()
            logger.info("âœ… ØªÙ… Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø£Ù…Ø§Ù†")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†: {e}")
    
    def _safe_sync_table(self, table_name: str) -> Dict[str, Any]:
        """Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ø­Ø¯ Ø¨Ø£Ù…Ø§Ù† Ù…Ø¹ ÙƒØ´Ù Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª"""
        result = {
            'synced': 0,
            'updated': 0,
            'conflicts': 0,
            'errors': 0
        }
        
        try:
            cursor = self.repo.sqlite_cursor
            
            # 1. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
            cloud_data = list(self.repo.mongo_db[table_name].find())
            cloud_ids = {str(item['_id']): item for item in cloud_data}
            
            # 2. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
            cursor.execute(f"SELECT * FROM {table_name}")
            local_rows = cursor.fetchall()
            
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = [col[1] for col in cursor.fetchall()]
            
            local_data = {}
            for row in local_rows:
                row_dict = dict(zip(columns, row))
                mongo_id = row_dict.get('_mongo_id')
                if mongo_id:
                    local_data[mongo_id] = row_dict
            
            # 3. Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
            for mongo_id, cloud_item in cloud_ids.items():
                try:
                    prepared_data = self._prepare_cloud_data_for_local(cloud_item)
                    prepared_data['_mongo_id'] = mongo_id
                    prepared_data['sync_status'] = 'synced'
                    
                    # ØªØµÙÙŠØ© Ø§Ù„Ø­Ù‚ÙˆÙ„
                    filtered_data = {k: v for k, v in prepared_data.items() if k in columns}
                    
                    if mongo_id in local_data:
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
                        local_record = local_data[mongo_id]
                        
                        # ÙƒØ´Ù Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
                        if self._has_conflict(local_record, filtered_data):
                            conflict_resolved = self._resolve_conflict(
                                table_name, local_record, filtered_data
                            )
                            if conflict_resolved:
                                filtered_data = conflict_resolved
                                result['conflicts'] += 1
                            else:
                                continue  # ØªØ®Ø·ÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¬Ù„
                        
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„
                        set_clause = ', '.join([f"{k}=?" for k in filtered_data.keys()])
                        values = list(filtered_data.values()) + [local_record['id']]
                        cursor.execute(
                            f"UPDATE {table_name} SET {set_clause} WHERE id=?",
                            values
                        )
                        result['updated'] += 1
                    else:
                        # Ø¥Ø¯Ø±Ø§Ø¬ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯
                        if filtered_data:
                            cols = ', '.join(filtered_data.keys())
                            placeholders = ', '.join(['?' for _ in filtered_data])
                            cursor.execute(
                                f"INSERT INTO {table_name} ({cols}) VALUES ({placeholders})",
                                list(filtered_data.values())
                            )
                            result['synced'] += 1
                
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© Ø³Ø¬Ù„ Ù…Ù† {table_name}: {e}")
                    result['errors'] += 1
            
            # 4. Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø³Ø­Ø§Ø¨Ø©
            self._push_local_changes(table_name)
            
            self.repo.sqlite_conn.commit()
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© {table_name}: {e}")
            result['errors'] += 1
        
        return result
    
    def _has_conflict(self, local_record: Dict, remote_data: Dict) -> bool:
        """ÙƒØ´Ù Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙˆØ§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©"""
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙ‚Ø·
        important_fields = ['name', 'title', 'description', 'amount', 'status', 'last_modified']
        
        for field in important_fields:
            if field in local_record and field in remote_data:
                local_val = str(local_record[field] or '').strip()
                remote_val = str(remote_data[field] or '').strip()
                
                if local_val != remote_val:
                    # ÙØ­Øµ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
                    local_modified = local_record.get('last_modified')
                    remote_modified = remote_data.get('last_modified')
                    
                    if local_modified and remote_modified:
                        try:
                            local_dt = datetime.fromisoformat(local_modified.replace('Z', '+00:00'))
                            remote_dt = datetime.fromisoformat(remote_modified.replace('Z', '+00:00'))
                            
                            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙØ±Ù‚ Ø£ÙƒØ«Ø± Ù…Ù† Ø¯Ù‚ÙŠÙ‚Ø©ØŒ ÙÙ‡Ù†Ø§Ùƒ ØªØ¹Ø§Ø±Ø¶
                            if abs((local_dt - remote_dt).total_seconds()) > 60:
                                return True
                        except (ValueError, TypeError):
                            return True
        
        return False
    
    def _resolve_conflict(self, table_name: str, local_record: Dict, 
                         remote_data: Dict) -> Optional[Dict]:
        """Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            cursor = self.repo.sqlite_cursor
            
            # Ø­ÙØ¸ Ø§Ù„ØªØ¹Ø§Ø±Ø¶ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            cursor.execute("""
                INSERT INTO sync_conflicts 
                (table_name, record_id, local_data, remote_data, created_at)
                VALUES (?, ?, ?, ?, ?)
            """, (
                table_name,
                local_record.get('id'),
                json.dumps(local_record, ensure_ascii=False, default=str),
                json.dumps(remote_data, ensure_ascii=False, default=str),
                datetime.now().isoformat()
            ))
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„ØªØ¹Ø§Ø±Ø¶
            self.data_conflict.emit(table_name, local_record, remote_data)
            
            # Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶ Ø­Ø³Ø¨ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯
            if self._conflict_resolution == 'local_wins':
                return local_record
            elif self._conflict_resolution == 'remote_wins':
                return remote_data
            elif self._conflict_resolution == 'merge':
                return self._merge_records(local_record, remote_data)
            else:
                # Ø§ÙØªØ±Ø§Ø¶ÙŠ: Ø§Ù„Ù…Ø­Ù„ÙŠ ÙŠÙÙˆØ²
                return local_record
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶: {e}")
            return local_record  # Ø§Ù„Ù…Ø­Ù„ÙŠ ÙŠÙÙˆØ² ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
    
    def _merge_records(self, local: Dict, remote: Dict) -> Dict:
        """Ø¯Ù…Ø¬ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ØªØ¹Ø§Ø±Ø¶Ø© Ø¨Ø°ÙƒØ§Ø¡"""
        merged = dict(local)  # Ù†Ø¨Ø¯Ø£ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
        merge_fields = ['_mongo_id', 'sync_status']
        for field in merge_fields:
            if field in remote:
                merged[field] = remote[field]
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø­Ø¯Ø« ØªØ§Ø±ÙŠØ® ØªØ¹Ø¯ÙŠÙ„
        local_modified = local.get('last_modified')
        remote_modified = remote.get('last_modified')
        
        if remote_modified and local_modified:
            try:
                local_dt = datetime.fromisoformat(local_modified.replace('Z', '+00:00'))
                remote_dt = datetime.fromisoformat(remote_modified.replace('Z', '+00:00'))
                
                if remote_dt > local_dt:
                    # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ© Ø£Ø­Ø¯Ø«
                    for field in ['name', 'title', 'description', 'amount', 'status']:
                        if field in remote:
                            merged[field] = remote[field]
            except (ValueError, TypeError):
                pass
        
        return merged
    
    def _push_local_changes(self, table_name: str):
        """Ø±ÙØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ù„Ù„Ø³Ø­Ø§Ø¨Ø©"""
        try:
            cursor = self.repo.sqlite_cursor
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
            cursor.execute(f"""
                SELECT * FROM {table_name}
                WHERE sync_status != 'synced' OR sync_status IS NULL
            """)
            local_changes = cursor.fetchall()
            
            if not local_changes:
                return
            
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = [col[1] for col in cursor.fetchall()]
            
            collection = self.repo.mongo_db[table_name]
            unique_field = self.UNIQUE_FIELDS.get(table_name, 'name')
            
            for row in local_changes:
                try:
                    row_dict = dict(zip(columns, row))
                    local_id = row_dict.get('id')
                    mongo_id = row_dict.get('_mongo_id')
                    
                    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø³Ø­Ø§Ø¨Ø©
                    cloud_data = self._prepare_local_data_for_cloud(row_dict)
                    
                    if mongo_id:
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
                        from bson import ObjectId
                        collection.update_one(
                            {'_id': ObjectId(mongo_id)},
                            {'$set': cloud_data}
                        )
                    else:
                        # ÙØ­Øµ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø£ÙˆÙ„Ø§Ù‹
                        unique_value = cloud_data.get(unique_field)
                        if unique_value:
                            existing = collection.find_one({unique_field: unique_value})
                            if existing:
                                # Ø±Ø¨Ø· Ø¨Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
                                mongo_id = str(existing['_id'])
                            else:
                                # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯
                                result = collection.insert_one(cloud_data)
                                mongo_id = str(result.inserted_id)
                        else:
                            # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯
                            result = collection.insert_one(cloud_data)
                            mongo_id = str(result.inserted_id)
                        
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ø­Ù„ÙŠ
                        cursor.execute(
                            f"UPDATE {table_name} SET _mongo_id=?, sync_status='synced' WHERE id=?",
                            (mongo_id, local_id)
                        )
                
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø³Ø¬Ù„ Ù…Ù† {table_name}: {e}")
            
            self.repo.sqlite_conn.commit()
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ ØªØºÙŠÙŠØ±Ø§Øª {table_name}: {e}")
    
    def _prepare_cloud_data_for_local(self, data: Dict) -> Dict:
        """ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø­Ø§Ø¨Ø© Ù„Ù„Ø­ÙØ¸ Ù…Ø­Ù„ÙŠØ§Ù‹"""
        item = dict(data)
        item.pop('_id', None)
        item.pop('id', None)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        date_fields = [
            'created_at', 'last_modified', 'date', 'issue_date',
            'due_date', 'start_date', 'end_date', 'last_login'
        ]
        for field in date_fields:
            if field in item and hasattr(item[field], 'isoformat'):
                item[field] = item[field].isoformat()
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… ÙˆØ§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø¥Ù„Ù‰ JSON
        json_fields = ['items', 'lines', 'data', 'milestones', 'tags']
        for field in json_fields:
            if field in item and isinstance(item[field], (list, dict)):
                item[field] = json.dumps(item[field], ensure_ascii=False)
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        now = datetime.now().isoformat()
        if not item.get('created_at'):
            item['created_at'] = now
        if not item.get('last_modified'):
            item['last_modified'] = now
        
        return item
    
    def _prepare_local_data_for_cloud(self, data: Dict) -> Dict:
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ù„Ù„Ø±ÙØ¹ Ù„Ù„Ø³Ø­Ø§Ø¨Ø©"""
        clean = {k: v for k, v in data.items()
                 if k not in ['id', '_mongo_id', 'sync_status']}
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        for field in ['created_at', 'last_modified', 'date', 'issue_date',
                     'due_date', 'start_date', 'end_date']:
            if field in clean and clean[field]:
                try:
                    if isinstance(clean[field], str):
                        clean[field] = datetime.fromisoformat(
                            clean[field].replace('Z', '+00:00')
                        )
                except (ValueError, TypeError):
                    pass
        
        # ØªØ­ÙˆÙŠÙ„ JSON strings Ø¥Ù„Ù‰ objects
        for field in ['items', 'lines', 'data', 'milestones', 'tags']:
            if field in clean and clean[field]:
                try:
                    if isinstance(clean[field], str):
                        clean[field] = json.loads(clean[field])
                except (json.JSONDecodeError, TypeError):
                    pass
        
        return clean
    
    def restore_from_backup(self, backup_name: str = None) -> bool:
        """Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù†Ù‚Ø·Ø© Ø§Ø³ØªØ¹Ø§Ø¯Ø©"""
        try:
            cursor = self.repo.sqlite_cursor
            
            if backup_name:
                cursor.execute(
                    "SELECT backup_data FROM sync_backups WHERE backup_name = ?",
                    (backup_name,)
                )
            else:
                cursor.execute(
                    "SELECT backup_data FROM sync_backups ORDER BY created_at DESC LIMIT 1"
                )
            
            backup_row = cursor.fetchone()
            if not backup_row:
                logger.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©")
                return False
            
            backup_data = json.loads(backup_row[0])
            
            # Ø§Ø³ØªØ¹Ø§Ø¯Ø© ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
            for table_name, table_data in backup_data.items():
                try:
                    # Ù…Ø³Ø­ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ
                    cursor.execute(f"DELETE FROM {table_name}")
                    
                    # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    for record in table_data:
                        if record:  # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
                            columns = ', '.join(record.keys())
                            placeholders = ', '.join(['?' for _ in record])
                            cursor.execute(
                                f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})",
                                list(record.values())
                            )
                    
                    logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© {len(table_data)} Ø³Ø¬Ù„ Ù…Ù† {table_name}")
                    
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© {table_name}: {e}")
            
            self.repo.sqlite_conn.commit()
            logger.info("âœ… ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            return False
    
    def get_sync_status(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©"""
        cursor = self.repo.sqlite_cursor
        
        status = {
            'is_online': self.is_online,
            'is_syncing': self._is_syncing,
            'tables': {},
            'conflicts': 0,
            'backups': 0
        }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        for table in self.SYNC_TABLES:
            try:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                total = cursor.fetchone()[0]
                
                cursor.execute(f"""
                    SELECT COUNT(*) FROM {table}
                    WHERE sync_status = 'synced'
                """)
                synced = cursor.fetchone()[0] if cursor.fetchone() else 0
                
                status['tables'][table] = {
                    'total': total,
                    'synced': synced,
                    'pending': total - synced
                }
            except Exception:
                status['tables'][table] = {'total': 0, 'synced': 0, 'pending': 0}
        
        # Ø¹Ø¯Ø¯ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
        try:
            cursor.execute("SELECT COUNT(*) FROM sync_conflicts WHERE resolution IS NULL")
            status['conflicts'] = cursor.fetchone()[0]
        except Exception:
            pass
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        try:
            cursor.execute("SELECT COUNT(*) FROM sync_backups")
            status['backups'] = cursor.fetchone()[0]
        except Exception:
            pass
        
        return status
    
    def set_conflict_resolution(self, strategy: str):
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª"""
        if strategy in ['local_wins', 'remote_wins', 'merge']:
            self._conflict_resolution = strategy
            logger.info(f"ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª: {strategy}")
        else:
            logger.warning(f"Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ØºÙŠØ± ØµØ­ÙŠØ­Ø©: {strategy}")


def create_sync_manager_v3(repository) -> SyncManagerV3:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯"""
    return SyncManagerV3(repository)