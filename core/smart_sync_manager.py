# Ø§Ù„Ù…Ù„Ù: core/smart_sync_manager.py
"""
ðŸ”„ Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø°ÙƒÙŠ Ù…Ø¹ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
ÙŠØ¯Ù…Ø¬ SyncManager Ù…Ø¹ ConflictResolver Ù„ØªÙˆÙÙŠØ±:
1. Smart Field-Level Merge
2. ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©
3. Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ø¹Ù†Ø¯ Ø­Ø¯ÙˆØ« ØªØ¹Ø§Ø±Ø¶Ø§Øª
"""

import json
import threading
from datetime import datetime
from typing import Any

from PyQt6.QtCore import QObject, pyqtSignal

from core.conflict_resolver import ConflictResolution, ConflictResolver
from core.logger import get_logger

logger = get_logger(__name__)


class SmartSyncManager(QObject):
    """
    ðŸ”„ Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø°ÙƒÙŠ
    ÙŠÙˆÙØ± Ù…Ø²Ø§Ù…Ù†Ø© Ø¢Ù…Ù†Ø© Ù…Ø¹ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ø°ÙƒÙŠ
    """

    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ (Ù„Ù„Ø­Ù…Ø§ÙŠØ© Ù…Ù† SQL Injection)
    ALLOWED_TABLES = frozenset({
        'accounts', 'clients', 'services', 'projects', 'invoices',
        'payments', 'expenses', 'journal_entries', 'quotations',
        'currencies', 'users', 'notifications', 'tasks', 'sync_queue'
    })

    # Ø¥Ø´Ø§Ø±Ø§Øª
    conflict_detected = pyqtSignal(dict)      # Ø¹Ù†Ø¯ Ø§ÙƒØªØ´Ø§Ù ØªØ¹Ø§Ø±Ø¶
    conflict_resolved = pyqtSignal(dict)      # Ø¹Ù†Ø¯ Ø­Ù„ ØªØ¹Ø§Ø±Ø¶
    critical_conflict = pyqtSignal(dict)      # ØªØ¹Ø§Ø±Ø¶ Ø­Ø³Ø§Ø³ ÙŠØªØ·Ù„Ø¨ Ù…Ø±Ø§Ø¬Ø¹Ø©
    sync_progress = pyqtSignal(str, int, int) # table, current, total

    def __init__(self, repository, parent=None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø°ÙƒÙŠ

        Args:
            repository: ÙƒØ§Ø¦Ù† Repository Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        """
        super().__init__(parent)
        self.repository = repository
        self.conflict_resolver = ConflictResolver(repository.sqlite_conn)
        self._lock = threading.RLock()

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.stats = {
            'total_synced': 0,
            'auto_merged': 0,
            'pending_review': 0,
            'conflicts_resolved': 0
        }

        logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© SmartSyncManager")

    def smart_pull_and_merge(self, collection_name: str) -> dict[str, int]:
        """
        Ø³Ø­Ø¨ ÙˆØ¯Ù…Ø¬ Ø°ÙƒÙŠ Ù…Ø¹ Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª

        Args:
            collection_name: Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©/Ø§Ù„Ø¬Ø¯ÙˆÙ„

        Returns:
            Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
        """
        if not self.repository.online:
            logger.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØµØ§Ù„ - ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©")
            return {'synced': 0, 'conflicts': 0, 'pending': 0}

        stats = {
            'synced': 0,
            'inserted': 0,
            'updated': 0,
            'conflicts': 0,
            'auto_merged': 0,
            'pending_review': 0
        }

        try:
            with self._lock:
                # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©
                cloud_data = list(self.repository.mongo_db[collection_name].find())

                if not cloud_data:
                    logger.info(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ {collection_name}")
                    return stats

                logger.info(f"ðŸ”„ Ø¬Ø§Ø±ÙŠ Ù…Ø²Ø§Ù…Ù†Ø© {len(cloud_data)} Ø³Ø¬Ù„ Ù…Ù† {collection_name}...")

                cursor = self.repository.sqlite_cursor
                conn = self.repository.sqlite_conn

                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„
                cursor.execute(f"PRAGMA table_info({collection_name})")
                table_columns = {row[1] for row in cursor.fetchall()}

                for i, cloud_item in enumerate(cloud_data):
                    self.sync_progress.emit(collection_name, i + 1, len(cloud_data))

                    result = self._process_cloud_item(
                        collection_name, cloud_item, cursor, table_columns
                    )

                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                    if result['action'] == 'inserted':
                        stats['inserted'] += 1
                    elif result['action'] == 'updated':
                        stats['updated'] += 1

                    if result.get('conflict'):
                        stats['conflicts'] += 1
                        if result['conflict'].resolution == ConflictResolution.AUTO_MERGED:
                            stats['auto_merged'] += 1
                        elif result['conflict'].resolution == ConflictResolution.PENDING_REVIEW:
                            stats['pending_review'] += 1
                            # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© Ù„Ù„ØªØ¹Ø§Ø±Ø¶ Ø§Ù„Ø­Ø³Ø§Ø³
                            self.critical_conflict.emit({
                                'table': collection_name,
                                'entity_id': result.get('entity_id'),
                                'conflict': result['conflict'].conflict_details
                            })

                conn.commit()
                stats['synced'] = stats['inserted'] + stats['updated']

                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
                self.stats['total_synced'] += stats['synced']
                self.stats['auto_merged'] += stats['auto_merged']
                self.stats['pending_review'] += stats['pending_review']

                logger.info(
                    f"âœ… {collection_name}: Ù…Ø²Ø§Ù…Ù†Ø© {stats['synced']} "
                    f"(Ø¬Ø¯ÙŠØ¯: {stats['inserted']}, ØªØ­Ø¯ÙŠØ«: {stats['updated']}, "
                    f"ØªØ¹Ø§Ø±Ø¶Ø§Øª: {stats['conflicts']})"
                )

        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø²Ø§Ù…Ù†Ø© {collection_name}: {e}")
            import traceback
            traceback.print_exc()

        return stats

    def _process_cloud_item(
        self,
        collection_name: str,
        cloud_item: dict[str, Any],
        cursor,
        table_columns: set
    ) -> dict[str, Any]:
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù†ØµØ± ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©

        Returns:
            dict Ù…Ø¹ action Ùˆ conflict (Ø¥Ù† ÙˆØ¬Ø¯)
        """
        mongo_id = str(cloud_item['_id'])
        unique_field = self._get_unique_field(collection_name)
        unique_value = cloud_item.get(unique_field)

        # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ
        local_record = self._find_local_record(
            cursor, collection_name, mongo_id, unique_field, unique_value
        )

        if not local_record:
            # Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯ - Ø¥Ø¯Ø±Ø§Ø¬ Ù…Ø¨Ø§Ø´Ø±
            self._insert_record(cursor, collection_name, cloud_item,
                               mongo_id, table_columns)
            return {'action': 'inserted', 'entity_id': mongo_id}

        # 2. Ø§Ù„Ø³Ø¬Ù„ Ù…ÙˆØ¬ÙˆØ¯ - ÙØ­Øµ Ø§Ù„ØªØ¹Ø§Ø±Ø¶
        local_id = local_record['id']
        local_dict = dict(local_record)
        cloud_dict = self._prepare_cloud_data(cloud_item)

        # 3. ÙƒØ´Ù ÙˆØ­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶
        conflict_result = self.conflict_resolver.detect_and_resolve(
            table_name=collection_name,
            entity_id=str(local_id),
            local_record=local_dict,
            remote_record=cloud_dict
        )

        if conflict_result.has_conflict:
            # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø©
            self.conflict_detected.emit({
                'table': collection_name,
                'entity_id': str(local_id),
                'resolution': conflict_result.resolution.value,
                'fields': conflict_result.conflicting_fields
            })

        # 4. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        if conflict_result.requires_review:
            # ØªØ¹Ø§Ø±Ø¶ Ø­Ø³Ø§Ø³ - Ù„Ø§ Ù†Ø­Ø¯Ø« Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø­Ø³Ø§Ø³Ø©
            # Ù†Ø­Ø¯Ø« ÙÙ‚Ø· Ø§Ù„Ø­Ù‚ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ø­Ø³Ø§Ø³Ø©
            safe_data = self._get_safe_fields(
                conflict_result.merged_data,
                collection_name
            )
            self._update_record(cursor, collection_name, local_id,
                               safe_data, table_columns)
        else:
            # Ø¯Ù…Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø£Ùˆ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ¹Ø§Ø±Ø¶
            self._update_record(cursor, collection_name, local_id,
                               conflict_result.merged_data, table_columns)

        return {
            'action': 'updated',
            'entity_id': str(local_id),
            'conflict': conflict_result if conflict_result.has_conflict else None
        }

    def _validate_table_name(self, table_name: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù„Ù„Ø­Ù…Ø§ÙŠØ© Ù…Ù† SQL Injection"""
        return table_name in self.ALLOWED_TABLES

    def _validate_column_name(self, column_name: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯"""
        # Ø§Ù„Ø³Ù…Ø§Ø­ ÙÙ‚Ø· Ø¨Ø§Ù„Ø£Ø­Ø±Ù ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø´Ø±Ø·Ø© Ø§Ù„Ø³ÙÙ„ÙŠØ©
        import re
        return bool(re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', column_name))

    def _find_local_record(
        self,
        cursor,
        collection_name: str,
        mongo_id: str,
        unique_field: str,
        unique_value: Any
    ) -> dict[str, Any] | None:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ"""
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„
        if not self._validate_table_name(collection_name):
            logger.error(f"Ø§Ø³Ù… Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± ØµØ§Ù„Ø­: {collection_name}")
            return None

        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ù€ mongo_id Ø£ÙˆÙ„Ø§Ù‹
        cursor.execute(
            f"SELECT * FROM {collection_name} WHERE _mongo_id = ?",
            (mongo_id,)
        )
        row = cursor.fetchone()

        if row:
            return dict(row)

        # Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„ÙØ±ÙŠØ¯ - Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯
        if unique_value and self._validate_column_name(unique_field):
            cursor.execute(
                f"SELECT * FROM {collection_name} WHERE {unique_field} = ?",
                (unique_value,)
            )
            row = cursor.fetchone()
            if row:
                return dict(row)

        return None

    def _insert_record(
        self,
        cursor,
        collection_name: str,
        cloud_item: dict[str, Any],
        mongo_id: str,
        table_columns: set
    ):
        """Ø¥Ø¯Ø±Ø§Ø¬ Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯"""
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„
        if not self._validate_table_name(collection_name):
            logger.error(f"Ø§Ø³Ù… Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± ØµØ§Ù„Ø­: {collection_name}")
            return

        item = self._prepare_cloud_data(cloud_item)
        item['_mongo_id'] = mongo_id
        item['sync_status'] = 'synced'

        if 'created_at' not in item or not item['created_at']:
            item['created_at'] = datetime.now().isoformat()
        if 'last_modified' not in item or not item['last_modified']:
            item['last_modified'] = datetime.now().isoformat()

        # ØªØµÙÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­ØªÙ‡Ø§
        filtered = {k: v for k, v in item.items()
                   if k in table_columns and self._validate_column_name(k)}

        if filtered:
            columns = ', '.join(filtered.keys())
            placeholders = ', '.join(['?' for _ in filtered])
            cursor.execute(
                f"INSERT INTO {collection_name} ({columns}) VALUES ({placeholders})",
                list(filtered.values())
            )

    def _update_record(
        self,
        cursor,
        collection_name: str,
        local_id: int,
        data: dict[str, Any],
        table_columns: set
    ):
        """ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ù…ÙˆØ¬ÙˆØ¯"""
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„
        if not self._validate_table_name(collection_name):
            logger.error(f"Ø§Ø³Ù… Ø¬Ø¯ÙˆÙ„ ØºÙŠØ± ØµØ§Ù„Ø­: {collection_name}")
            return

        data['sync_status'] = 'synced'
        data['last_modified'] = datetime.now().isoformat()

        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ­Ø¯ÙŠØ«
        data.pop('id', None)
        data.pop('created_at', None)

        # ØªØµÙÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­ØªÙ‡Ø§
        filtered = {k: v for k, v in data.items()
                   if k in table_columns and self._validate_column_name(k)}

        if filtered:
            set_clause = ', '.join([f"{k}=?" for k in filtered.keys()])
            values = list(filtered.values()) + [local_id]
            cursor.execute(
                f"UPDATE {collection_name} SET {set_clause} WHERE id=?",
                values
            )

    def _get_safe_fields(
        self,
        data: dict[str, Any],
        collection_name: str
    ) -> dict[str, Any]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¢Ù…Ù†Ø© ÙÙ‚Ø· (ØºÙŠØ± Ø§Ù„Ø­Ø³Ø§Ø³Ø©)
        Ù„Ù„ØªØ­Ø¯ÙŠØ« Ø¹Ù†Ø¯ ÙˆØ¬ÙˆØ¯ ØªØ¹Ø§Ø±Ø¶ Ø­Ø³Ø§Ø³
        """
        critical_fields = ConflictResolver.CRITICAL_FIELDS.get(collection_name, [])
        return {k: v for k, v in data.items() if k not in critical_fields}

    def _prepare_cloud_data(self, data: dict[str, Any]) -> dict[str, Any]:
        """ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø­Ø§Ø¨Ø©"""
        item = dict(data)
        item.pop('_id', None)
        item.pop('id', None)

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        for field in ['created_at', 'last_modified', 'date', 'issue_date',
                     'due_date', 'expiry_date', 'start_date', 'end_date']:
            if field in item and hasattr(item[field], 'isoformat'):
                item[field] = item[field].isoformat()

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù… Ø¥Ù„Ù‰ JSON
        for field in ['items', 'lines', 'data', 'milestones']:
            if field in item and isinstance(item[field], (list, dict)):
                item[field] = json.dumps(item[field], ensure_ascii=False)

        return item

    def _get_unique_field(self, table_name: str) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„ÙØ±ÙŠØ¯ Ù„ÙƒÙ„ Ø¬Ø¯ÙˆÙ„"""
        unique_fields = {
            'clients': 'name',
            'projects': 'name',
            'services': 'name',
            'accounts': 'code',
            'expenses': 'id',
            'invoices': 'invoice_number',
            'payments': 'id',
            'journal_entries': 'id',
            'quotations': 'quote_number',
            'currencies': 'code',
            'users': 'username',
            'notifications': 'id'
        }
        return unique_fields.get(table_name, 'name')

    # ==========================================
    # ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
    # ==========================================

    def full_smart_sync(self) -> dict[str, Any]:
        """
        Ù…Ø²Ø§Ù…Ù†Ø© ÙƒØ§Ù…Ù„Ø© Ø°ÙƒÙŠØ© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„

        Returns:
            Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        """
        if not self.repository.online:
            logger.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§ØªØµØ§Ù„ - ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©")
            return {'success': False, 'reason': 'offline'}

        logger.info("=" * 60)
        logger.info("ðŸ”„ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©")
        logger.info("=" * 60)

        start_time = datetime.now()

        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        tables = [
            'accounts',      # Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø£ÙˆÙ„Ø§Ù‹ (Ø£Ø³Ø§Ø³ÙŠØ©)
            'clients',       # Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
            'services',      # Ø§Ù„Ø®Ø¯Ù…Ø§Øª
            'projects',      # Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹
            'invoices',      # Ø§Ù„ÙÙˆØ§ØªÙŠØ±
            'payments',      # Ø§Ù„Ø¯ÙØ¹Ø§Øª
            'expenses',      # Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª
            'journal_entries', # Ø§Ù„Ù‚ÙŠÙˆØ¯
            'quotations',    # Ø¹Ø±ÙˆØ¶ Ø§Ù„Ø£Ø³Ø¹Ø§Ø±
            'currencies',    # Ø§Ù„Ø¹Ù…Ù„Ø§Øª
            'notifications', # Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª
        ]

        results = {}
        total_stats = {
            'synced': 0,
            'conflicts': 0,
            'auto_merged': 0,
            'pending_review': 0
        }

        for table in tables:
            try:
                stats = self.smart_pull_and_merge(table)
                results[table] = stats

                total_stats['synced'] += stats.get('synced', 0)
                total_stats['conflicts'] += stats.get('conflicts', 0)
                total_stats['auto_merged'] += stats.get('auto_merged', 0)
                total_stats['pending_review'] += stats.get('pending_review', 0)

            except Exception as e:
                logger.error(f"âŒ ÙØ´Ù„ Ù…Ø²Ø§Ù…Ù†Ø© {table}: {e}")
                results[table] = {'synced': 0, 'conflicts': 0, 'auto_merged': 0, 'pending_review': 0}

        elapsed = (datetime.now() - start_time).total_seconds()

        logger.info("=" * 60)
        logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø°ÙƒÙŠØ© ÙÙŠ {elapsed:.1f} Ø«Ø§Ù†ÙŠØ©")
        logger.info(f"   ðŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_stats['synced']} Ø³Ø¬Ù„")
        logger.info(f"   ðŸ”„ ØªØ¹Ø§Ø±Ø¶Ø§Øª: {total_stats['conflicts']}")
        logger.info(f"   âœ… Ø¯Ù…Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠ: {total_stats['auto_merged']}")
        logger.info(f"   âš ï¸ Ø¨Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©: {total_stats['pending_review']}")
        logger.info("=" * 60)

        return {
            'success': True,
            'elapsed_seconds': elapsed,
            'tables': results,
            'totals': total_stats
        }

    # ==========================================
    # ÙˆØ§Ø¬Ù‡Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
    # ==========================================

    def get_pending_conflicts(self) -> list[dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©"""
        result: list[dict[str, Any]] = self.conflict_resolver.get_pending_conflicts()
        return result

    def get_pending_conflicts_count(self) -> int:
        """Ø¹Ø¯Ø¯ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©"""
        return int(self.conflict_resolver.get_pending_count())

    def resolve_conflict(
        self,
        conflict_id: int,
        chosen_version: str,
        merged_data: dict[str, Any] | None = None,
        notes: str = ""
    ) -> bool:
        """
        Ø­Ù„ ØªØ¹Ø§Ø±Ø¶ ÙŠØ¯ÙˆÙŠØ§Ù‹

        Args:
            conflict_id: Ù…Ø¹Ø±Ù Ø§Ù„ØªØ¹Ø§Ø±Ø¶
            chosen_version: 'local' Ø£Ùˆ 'remote' Ø£Ùˆ 'merged'
            merged_data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø© (Ø¥Ø°Ø§ ÙƒØ§Ù† merged)
            notes: Ù…Ù„Ø§Ø­Ø¸Ø§Øª
        """
        success = self.conflict_resolver.resolve_conflict_manually(
            conflict_id=conflict_id,
            chosen_version=chosen_version,
            merged_data=merged_data,
            notes=notes
        )

        if success:
            self.stats['conflicts_resolved'] += 1
            self.conflict_resolved.emit({
                'conflict_id': conflict_id,
                'chosen_version': chosen_version
            })

        return bool(success)

    def get_conflict_history(self, limit: int = 50) -> list[dict[str, Any]]:
        """Ø¬Ù„Ø¨ Ø³Ø¬Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª"""
        result: list[dict[str, Any]] = self.conflict_resolver.get_conflict_history(limit=limit)
        return result

    def get_stats(self) -> dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©"""
        return {
            **self.stats,
            'pending_conflicts': self.get_pending_conflicts_count()
        }

    def cleanup(self, days_old: int = 30):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        self.conflict_resolver.cleanup_old_conflicts(days_old)


# ==========================================
# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ø¥Ù†Ø´Ø§Ø¡
# ==========================================

def create_smart_sync_manager(repository) -> SmartSyncManager:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ù…Ø²Ø§Ù…Ù†Ø© Ø°ÙƒÙŠ Ø¬Ø¯ÙŠØ¯"""
    return SmartSyncManager(repository)
